{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Club: Machine Learning Capstone Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from time import strptime  # format data columns\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # ignore warnings throughout notebook\n",
    "pd.set_option(\"display.max_columns\", None)  # show all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "filepath = \"../data/accepted_subsampled_5percent.csv\" #will be personalized\n",
    "df = pd.read_csv(filepath, sep=\",\")\n",
    "\n",
    "df_cleaned = df.copy() #work from second copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features known to investors based on LC website\n",
    "known_vars = ['acc_now_delinq',             # accounts now deliquent\n",
    "              'collections_12_mths_ex_med', # collections excluding medical\n",
    "              'fico_range_high',            # credit score range\n",
    "              'fico_range_low',             # creit score range\n",
    "              'delinq_2yrs',                # delinquencies in last two years\n",
    "              'delinq_amnt',                # delinquency amount\n",
    "              'earliest_cr_line',           # earliest credit line\n",
    "              'home_ownership',             # home ownership\n",
    "              'dti',                        # debt2income ratio\n",
    "              'annual_inc',                 # annual income\n",
    "              'initial_list_status',        # initial listing status\n",
    "              'inq_last_6mths',             # credit inquires in last 6mo\n",
    "              'int_rate',                   # interest rate\n",
    "              'verification_status_joint',  # is this a joint app\n",
    "              'emp_length',                 # length of employment (yr)\n",
    "              'loan_amnt',                  # loan amount\n",
    "              'id',                         # loan id\n",
    "              'purpose',                    # purpose of the loan\n",
    "              'term',                       # loan term (3 or 5yr)\n",
    "              'addr_state',                 # borrower location state\n",
    "              'installment',                # montly payment\n",
    "              'mths_since_last_delinq',     # mo since last delinquency\n",
    "              'mths_since_last_major_derog',# mo since last maj. derogatory\n",
    "              'mths_since_last_record',     # mo since last public record\n",
    "              'open_acc',                   # open credit line\n",
    "              'pub_rec',                    # public records on file\n",
    "              'revol_util',                 # revolving balance utilization (%)\n",
    "              'revol_bal',                  # revolving credit balance ($)\n",
    "              'tot_coll_amt',               # total collection amount ever\n",
    "              'total_acc',                  # total credit lines\n",
    "              'tot_cur_bal',                # total current balance\n",
    "              'verification_status',        # verified income (Y/N I think)\n",
    "              'grade'                       # loan grade\n",
    "             ]\n",
    "\n",
    "# Sanity check, print variable if not found within original dataframe\n",
    "# [ print(var) for var in known_vars if (var not in df.columns)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Missing Data of Known Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verification_status_joint      0.949313\n",
       "mths_since_last_record         0.838543\n",
       "mths_since_last_major_derog    0.744395\n",
       "mths_since_last_delinq         0.513786\n",
       "emp_length                     0.063868\n",
       "tot_cur_bal                    0.033430\n",
       "tot_coll_amt                   0.033430\n",
       "revol_util                     0.001006\n",
       "dti                            0.000829\n",
       "collections_12_mths_ex_med     0.000476\n",
       "open_acc                       0.000185\n",
       "pub_rec                        0.000185\n",
       "total_acc                      0.000185\n",
       "inq_last_6mths                 0.000185\n",
       "earliest_cr_line               0.000185\n",
       "delinq_amnt                    0.000185\n",
       "delinq_2yrs                    0.000185\n",
       "acc_now_delinq                 0.000185\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assess missingness of known variables\n",
    "missingness = df_cleaned[known_vars].isnull().mean().T\n",
    "missingness = missingness.loc[missingness>0].sort_values(ascending=False)\n",
    "missingness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop features missing > 50% \n",
    "feat_wManyMissing = missingness.index[np.where(missingness > .5)].to_list()\n",
    "df_cleaned[known_vars].drop(df_cleaned[feat_wManyMissing], axis=1, inplace=True)\n",
    "[known_vars.remove(var) for var in feat_wManyMissing] #remove features from known_var list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace NA's of numeric 'known_var' features with mean value\n",
    "numeric_var = ['tot_cur_bal',\n",
    "               'tot_coll_amt',\n",
    "               'revol_util',\n",
    "               'collections_12_mths_ex_med',\n",
    "               'open_acc',\n",
    "               'pub_rec',\n",
    "               'total_acc',\n",
    "               'inq_last_6mths',\n",
    "               'delinq_amnt',\n",
    "               'delinq_2yrs',\n",
    "               'dti' ]\n",
    "\n",
    "# List comprehension through numerica variables\n",
    "[df_cleaned[var].fillna(df[var].mean(), inplace=True) for var in numeric_var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper function to replace missing character strings with randomly selected value\n",
    "def fillna_random(var):\n",
    "    #find index of missing values\n",
    "    miss_idx = df_cleaned.loc[ df_cleaned[var].isnull()].index.tolist()\n",
    "    \n",
    "    #find new values to replace NaN values\n",
    "    new_val = df_cleaned[var].loc[~df_cleaned.index.isin(miss_idx)].sample(len(miss_idx)).values.tolist()\n",
    "\n",
    "    #replace values\n",
    "    df_cleaned[var][miss_idx] = new_val\n",
    "\n",
    "# ==================================================\n",
    "# Replace NA's of character 'known_var' features with random\n",
    "non_numeric_var = ['emp_length', 'earliest_cr_line', 'acc_now_delinq', 'delinq_2yrs'] #list of non-numeric variables\n",
    "[fillna_random(var) for var in non_numeric_var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc_now_delinq                0\n",
       "collections_12_mths_ex_med    0\n",
       "fico_range_high               0\n",
       "fico_range_low                0\n",
       "delinq_2yrs                   0\n",
       "delinq_amnt                   0\n",
       "earliest_cr_line              0\n",
       "home_ownership                0\n",
       "dti                           0\n",
       "annual_inc                    0\n",
       "initial_list_status           0\n",
       "inq_last_6mths                0\n",
       "int_rate                      0\n",
       "emp_length                    0\n",
       "loan_amnt                     0\n",
       "id                            0\n",
       "purpose                       0\n",
       "term                          0\n",
       "addr_state                    0\n",
       "installment                   0\n",
       "open_acc                      0\n",
       "pub_rec                       0\n",
       "revol_util                    0\n",
       "revol_bal                     0\n",
       "tot_coll_amt                  0\n",
       "total_acc                     0\n",
       "tot_cur_bal                   0\n",
       "verification_status           0\n",
       "grade                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check that no more missing values\n",
    "df_cleaned[known_vars].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify loan status (non-FullyPaid or ChargedOff loans will be converted to NAN)\n",
    "df_cleaned['loan_status'] = df_cleaned['loan_status'].map({'Fully Paid':'Fully Paid',\n",
    "                                                           'Charged Off':'Charged Off',\n",
    "                                                           'Does not meet the credit policy. Status:Fully Paid': 'Fully Paid',\n",
    "                                                           'Does not meet the credit policy. Status:Charged Off': 'Charged Off'})\n",
    "\n",
    "# Remove non-completed loans\n",
    "df_cleaned.drop(df_cleaned.loc[df_cleaned['loan_status'].isnull()].index.tolist(), axis=0, inplace=True)\n",
    "\n",
    "# Simplify home ownership\n",
    "df_cleaned['home_ownership'] = df_cleaned['home_ownership'].map({'MORTGAGE':'mortgage',\n",
    "                                                                 'OWN':'own',\n",
    "                                                                 'RENT':'rent'})\n",
    "\n",
    "# Remove 25 observations without houses\n",
    "df_cleaned.drop(df_cleaned.loc[df_cleaned['home_ownership'].isnull()].index.tolist(), axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Reformat date features and calculate features related to prepayment  \n",
    "df_cleaned['term_year'] = np.where(df_cleaned['term']==' 36 months', 3,5)\n",
    "df_cleaned['earliest_cr_line'] =  pd.to_datetime(df_cleaned['earliest_cr_line'])\n",
    "df_cleaned['issue_date'] =  pd.to_datetime(df_cleaned['issue_d'])\n",
    "df_cleaned['last_pymnt_date'] = pd.to_datetime(df_cleaned['last_pymnt_d'])\n",
    "df_cleaned['exp_last_pymnt_date'] = pd.to_datetime(df_cleaned['issue_d'].str[0:3]\n",
    "                                                   +'-'\n",
    "                                                   + (df_cleaned['issue_d'].str[-4:].astype('int')\n",
    "                                                   + df_cleaned['term_year']).astype('str'))\n",
    "\n",
    "# Calculate credit history ( in months )\n",
    "date_ofloan = df_cleaned['issue_date'].dt.to_period('M').astype(int)\n",
    "date_credline = df_cleaned['earliest_cr_line'].dt.to_period('M').astype(int)\n",
    "df_cleaned['credit_hist_mths'] = date_ofloan - date_credline\n",
    "df_cleaned['credit_hist_mths'] = np.where(df_cleaned['credit_hist_mths'] < 0, 0, df_cleaned['credit_hist_mths'])\n",
    "\n",
    "# Log-transform skewed continuous features\n",
    "df_cleaned['delinq_amnt_log'] = df_cleaned['delinq_amnt'].add(1).apply(np.log)\n",
    "df_cleaned['annual_inc_log'] = df_cleaned['annual_inc'].add(1).apply(np.log)\n",
    "df_cleaned['dti_log'] = df_cleaned['dti'].add(1).apply(np.log)\n",
    "df_cleaned['funded_amnt_log'] = df_cleaned['funded_amnt'].add(1).apply(np.log)\n",
    "df_cleaned['tot_coll_amt_log'] = df_cleaned['tot_coll_amt'].add(1).apply(np.log)\n",
    "df_cleaned['tot_cur_bal_log'] = df_cleaned['tot_cur_bal'].add(1).apply(np.log)\n",
    "df_cleaned['total_acc_log'] = df_cleaned['total_acc'].add(1).apply(np.log)\n",
    "df_cleaned['revol_bal_log'] = df_cleaned['revol_bal'].add(1).apply(np.log)\n",
    "df_cleaned['installment_log'] = df_cleaned['installment'].add(1).apply(np.log)\n",
    "df_cleaned['open_acc_log'] = df_cleaned['open_acc'].add(1).apply(np.log)\n",
    "\n",
    "# Simplify loan purpose - debt consolidation, credit card, and other\n",
    "df_cleaned['purpose'] = df_cleaned['purpose'].map({'debt_consolidation':'debt_consolidation',\n",
    "                                                   'credit_card':'credit_card'})\n",
    "df_cleaned['purpose'].fillna('other',inplace=True)\n",
    "\n",
    "# Convert loan grade to ordinal feature\n",
    "df_cleaned['grade'] = df_cleaned['grade'].map({'A':1,\n",
    "                                               'B':2,\n",
    "                                               'C':3,\n",
    "                                               'D':4,\n",
    "                                               'E':5,\n",
    "                                               'F':6,\n",
    "                                               'G':7})\n",
    "\n",
    "# Simplify employment length to four categories\n",
    "df_cleaned['emp_length'] = df_cleaned['emp_length'].map({'< 1 year':0.5,\n",
    "                                                         '1 year':1,\n",
    "                                                         '2 years':2,\n",
    "                                                         '3 years':3,\n",
    "                                                         '4 years':4,\n",
    "                                                         '5 years':5,\n",
    "                                                         '6 years':6,\n",
    "                                                         '7 years':7,\n",
    "                                                         '8 years':8,\n",
    "                                                         '9 years':9,\n",
    "                                                         '10+ years':10})\n",
    "\n",
    "# Create new binary features\n",
    "df_cleaned['has_pub_rec'] = np.where(df_cleaned['pub_rec']>0,1,0) #0-=no public record\n",
    "df_cleaned['has_paid_early'] = np.where((df_cleaned.loan_status=='Fully Paid')&(df_cleaned.last_pymnt_date < df_cleaned.exp_last_pymnt_date), 1, 0)\n",
    "df_cleaned['has_36mo_loan'] = np.where(df_cleaned['term'].str.contains('36'),1,0) #0=60mo loan\n",
    "df_cleaned['has_delinq_now'] = np.where(df_cleaned['acc_now_delinq']>0, 1, 0)\n",
    "df_cleaned['has_delinq_past2yrs'] = np.where(df_cleaned['delinq_2yrs']>0, 1, 0) #0=no delinq within 2yrs\n",
    "df_cleaned['has_whole_liststatus'] = np.where(df_cleaned['initial_list_status']=='w', 1, 0) #0=f\n",
    "df_cleaned['has_fullypaid'] = np.where(df_cleaned['loan_status']=='Fully Paid', 1, 0) #0=charged off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of loans above threadhold: 0.838\n"
     ]
    }
   ],
   "source": [
    "# Create response variable based on \n",
    "threshold = -20 #goal % return\n",
    "df_cleaned[\"roi_perc\"] = df_cleaned[\"total_pymnt\"].div(df_cleaned[\"funded_amnt\"]).sub(1).mul(100)\n",
    "df_cleaned['roi_response'] = np.where(df_cleaned['roi_perc'] > threshold, 1, 0)\n",
    "\n",
    "print('Fraction of loans above threadhold: %.3f' % df_cleaned['roi_response'].mean())\n",
    "\n",
    "# ==================================================================\n",
    "# Majority class [1] = ROI >-20% (IDEAL)\n",
    "# Minority class [0] = ROI <-20% (BAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate list of predictor variables to be used for ML\n",
    "predictor_vars = ['annual_inc_log',\n",
    "                  'credit_hist_mths',\n",
    "                  'delinq_amnt_log',\n",
    "                  'dti_log',\n",
    "                  'emp_length',\n",
    "                  'fico_range_high',\n",
    "                  'funded_amnt_log',\n",
    "                  'grade',\n",
    "                  'has_36mo_loan',\n",
    "                  'has_delinq_now',\n",
    "                  'has_delinq_past2yrs',\n",
    "                  'has_pub_rec',\n",
    "                  'has_whole_liststatus',\n",
    "                  'home_ownership',\n",
    "                  'inq_last_6mths',\n",
    "                  'installment_log',\n",
    "                  'int_rate',\n",
    "                  'open_acc_log',\n",
    "                  'purpose',\n",
    "                  'revol_bal_log',\n",
    "                  'revol_util',\n",
    "                  'tot_coll_amt_log',\n",
    "                  'tot_cur_bal_log',\n",
    "                  'total_acc_log',\n",
    "                  'verification_status']\n",
    "\n",
    "response_var = 'roi_response'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "- Goal is to build classifier that predicts if loan results in desirable outcome\n",
    "- Should also report feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify categorical features\n",
    "home_ownership_dummy = pd.get_dummies(df_cleaned['home_ownership'],\n",
    "                                      prefix=\"home_ownership\").drop('home_ownership_mortgage',axis=1)\n",
    "\n",
    "purpose_dummy = pd.get_dummies(df_cleaned['purpose'],\n",
    "                               prefix=\"purpose\").drop('purpose_debt_consolidation',axis=1)\n",
    "\n",
    "verification_status_dummy = pd.get_dummies(df_cleaned['verification_status'],\n",
    "                               prefix=\"verification_status\").drop('verification_status_Source Verified',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numeric features in the final dataframe\n",
    "numeric_vars = ['annual_inc_log',\n",
    "                'credit_hist_mths',\n",
    "                'delinq_amnt_log',\n",
    "                'dti_log',\n",
    "                'emp_length',\n",
    "                'fico_range_high',\n",
    "                'funded_amnt_log',\n",
    "                'grade',\n",
    "                'has_36mo_loan',\n",
    "                'has_delinq_now',\n",
    "                'has_delinq_past2yrs',\n",
    "                'has_pub_rec',\n",
    "                'has_whole_liststatus',\n",
    "                'inq_last_6mths',\n",
    "                'installment_log',\n",
    "                'int_rate',\n",
    "                'open_acc_log',\n",
    "                'revol_bal_log',\n",
    "                'revol_util',\n",
    "                'tot_coll_amt_log',\n",
    "                'tot_cur_bal_log',\n",
    "                'total_acc_log']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataframe for model consumption\n",
    "df_feature_final = pd.concat([df_cleaned[numeric_vars],\n",
    "                      home_ownership_dummy,\n",
    "                      purpose_dummy,\n",
    "                      verification_status_dummy],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-Based Model\n",
    "- Goal is to build classifier that predicts if loan results in desirable outcome\n",
    "- Should also report feature importance\n",
    "\n",
    "- Initially explored Random Forest algorithm but switched to XGboost due to time constraint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, precision_score, auc, recall_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive XGBoost Model - Imbalanced Data (83.8% ROI>-20%)\n",
    "\n",
    "*Goal is to minimize false positives* - Maximixe precision\n",
    "- Majority class [1] = ROI >-20% (IDEAL)\n",
    "- Minority class [0] = ROI <-20% (BAD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create test-train split of data\n",
    "x = df_feature_final\n",
    "y = df_cleaned[response_var] #labels\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc_PR': 0.8409,\n",
       " 'accuracy': 0.8384,\n",
       " 'recall': 0.9957,\n",
       " 'precision': 0.8409,\n",
       " 'false_discovery_rate': 0.1591,\n",
       " 'false_pos_rate': 0.9799,\n",
       " 'error_rate': 0.1616,\n",
       " 'n_true_pos': 11325,\n",
       " 'n_false_pos': 2143}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create random forest object\n",
    "naive_model = xgb.XGBClassifier(objective = 'binary:logistic', \n",
    "                                seed = 0)\n",
    "\n",
    "#Fit model with data\n",
    "naive_model.fit(x_train, y_train)\n",
    "\n",
    "#Analyze\n",
    "model = naive_model\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, model.predict(x_test)).ravel()\n",
    "results = {'auc_PR': round(average_precision_score(y_test, model.predict(x_test)),4),\n",
    "           'accuracy': round((tp + tn) / (tp + tn + fn + fp),4),\n",
    "           'recall': round(tp / (tp + fn),4),\n",
    "           'precision': round(tp/(tp+fp),4),\n",
    "           'false_discovery_rate': round(fp/(fp+tp),4),\n",
    "           'false_pos_rate': round(fp / (tn + fp),4),\n",
    "           'error_rate': round((fp + fn) / (tp + tn + fn + fp),4),\n",
    "           'n_true_pos':tp,\n",
    "           'n_false_pos':fp}\n",
    "results\n",
    "\n",
    "# # ==================== Print Results ====================\n",
    "# model = naive_model\n",
    "# y_pred = model.predict(x_test)\n",
    "# auc_PR = average_precision_score(y_test, y_pred)\n",
    "# precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "# plt.plot(recall, precision)\n",
    "# plt.xlabel('Recall (True Positive) ')\n",
    "# plt.ylabel('Precision (Proportion Correct)')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.title('Binary Precision-Recall curve: '\n",
    "#                    'auc_PR={0:0.2f}'.format(auc_PR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive XGBoost Model - using scale_pos_weight parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': 0.1929,\n",
       " 'auc_PR': 0.8827,\n",
       " 'accuracy': 0.6406,\n",
       " 'recall': 0.636,\n",
       " 'precision': 0.9079,\n",
       " 'false_discovery_rate': 0.0921,\n",
       " 'false_pos_rate': 0.3356,\n",
       " 'error_rate': 0.3594,\n",
       " 'n_true_pos': 7234,\n",
       " 'n_false_pos': 734}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create random forest object\n",
    "#scale_pos_weight = sum(negative) / sum(positive)\n",
    "naive_spw_model = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                                    scale_pos_weight=(len(y)-y.sum())/y.sum(), #0.1929\n",
    "                                    seed = 0)\n",
    "\n",
    "#Fit model with data\n",
    "naive_spw_model.fit(x_train, y_train)\n",
    "\n",
    "#Analyze\n",
    "model = naive_spw_model\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, model.predict(x_test)).ravel()\n",
    "naive_spw_results = {'weight': round((len(y)-y.sum())/y.sum(),4),\n",
    "                     'auc_PR': round(average_precision_score(y_test, model.predict(x_test)),4),\n",
    "                     'accuracy': round((tp + tn) / (tp + tn + fn + fp),4),\n",
    "                     'recall': round(tp / (tp + fn),4),\n",
    "                     'precision': round(tp/(tp+fp),4),\n",
    "                     'false_discovery_rate': round(fp/(fp+tp),4),\n",
    "                     'false_pos_rate': round(fp / (tn + fp),4),\n",
    "                     'error_rate': round((fp + fn) / (tp + tn + fn + fp),4),\n",
    "                     'n_true_pos':tp,\n",
    "                     'n_false_pos':fp}\n",
    "naive_spw_results\n",
    "\n",
    "# # ==================== Print Results ====================\n",
    "# model = naive_model\n",
    "# y_pred = model.predict(x_test)\n",
    "# auc_PR = average_precision_score(y_test, y_pred)\n",
    "# precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "# plt.plot(recall, precision)\n",
    "# plt.xlabel('Recall (True Positive) ')\n",
    "# plt.ylabel('Precision (Proportion Correct)')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.title('Binary Precision-Recall curve: '\n",
    "#                    'auc_PR={0:0.2f}'.format(auc_PR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune scale_pos_weight parameter based on area under the Precision-Recall curve (auc_PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 48s, sys: 665 ms, total: 2min 49s\n",
      "Wall time: 2min 49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>auc_PR</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>false_discovery_rate</th>\n",
       "      <th>false_pos_rate</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>n_true_pos</th>\n",
       "      <th>n_false_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.8834</td>\n",
       "      <td>0.5983</td>\n",
       "      <td>0.5731</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>6519.0</td>\n",
       "      <td>593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.8830</td>\n",
       "      <td>0.5797</td>\n",
       "      <td>0.5466</td>\n",
       "      <td>0.9197</td>\n",
       "      <td>0.0803</td>\n",
       "      <td>0.2483</td>\n",
       "      <td>0.4203</td>\n",
       "      <td>6217.0</td>\n",
       "      <td>543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.8829</td>\n",
       "      <td>0.6342</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>0.9093</td>\n",
       "      <td>0.0907</td>\n",
       "      <td>0.3251</td>\n",
       "      <td>0.3658</td>\n",
       "      <td>7124.0</td>\n",
       "      <td>711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.8829</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>0.6033</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>0.3027</td>\n",
       "      <td>0.3815</td>\n",
       "      <td>6862.0</td>\n",
       "      <td>662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.5570</td>\n",
       "      <td>0.5141</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.2199</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>5847.0</td>\n",
       "      <td>481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.8823</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>0.9293</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.4660</td>\n",
       "      <td>5471.0</td>\n",
       "      <td>416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8821</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>7428.0</td>\n",
       "      <td>778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.5115</td>\n",
       "      <td>0.4501</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.1687</td>\n",
       "      <td>0.4885</td>\n",
       "      <td>5119.0</td>\n",
       "      <td>369.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.4842</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.9389</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>0.1395</td>\n",
       "      <td>0.5158</td>\n",
       "      <td>4684.0</td>\n",
       "      <td>305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>0.3760</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.1143</td>\n",
       "      <td>0.5418</td>\n",
       "      <td>4277.0</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8756</td>\n",
       "      <td>0.4301</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>0.9473</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.0983</td>\n",
       "      <td>0.5699</td>\n",
       "      <td>3861.0</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.8716</td>\n",
       "      <td>0.3978</td>\n",
       "      <td>0.2980</td>\n",
       "      <td>0.9490</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>0.6022</td>\n",
       "      <td>3389.0</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.8666</td>\n",
       "      <td>0.3616</td>\n",
       "      <td>0.2524</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.0704</td>\n",
       "      <td>0.6384</td>\n",
       "      <td>2871.0</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>0.3343</td>\n",
       "      <td>0.2163</td>\n",
       "      <td>0.9557</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>2460.0</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>0.9607</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.2752</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.7248</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>0.1082</td>\n",
       "      <td>0.9678</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.7510</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.8477</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.9711</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>774.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>354.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8396</td>\n",
       "      <td>0.1658</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8342</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    weight  auc_PR  accuracy  recall  precision  false_discovery_rate  \\\n",
       "16    0.17  0.8834    0.5983  0.5731     0.9166                0.0834   \n",
       "15    0.16  0.8830    0.5797  0.5466     0.9197                0.0803   \n",
       "18    0.19  0.8829    0.6342  0.6263     0.9093                0.0907   \n",
       "17    0.18  0.8829    0.6185  0.6033     0.9120                0.0880   \n",
       "14    0.15  0.8826    0.5570  0.5141     0.9240                0.0760   \n",
       "13    0.14  0.8823    0.5340  0.4810     0.9293                0.0707   \n",
       "19    0.20  0.8821    0.6516  0.6531     0.9052                0.0948   \n",
       "12    0.13  0.8810    0.5115  0.4501     0.9328                0.0672   \n",
       "11    0.12  0.8800    0.4842  0.4118     0.9389                0.0611   \n",
       "10    0.11  0.8786    0.4582  0.3760     0.9448                0.0552   \n",
       "9     0.10  0.8756    0.4301  0.3395     0.9473                0.0527   \n",
       "8     0.09  0.8716    0.3978  0.2980     0.9490                0.0510   \n",
       "7     0.08  0.8666    0.3616  0.2524     0.9491                0.0509   \n",
       "6     0.07  0.8640    0.3343  0.2163     0.9557                0.0443   \n",
       "5     0.06  0.8602    0.3030  0.1762     0.9607                0.0393   \n",
       "4     0.05  0.8566    0.2752  0.1408     0.9656                0.0344   \n",
       "3     0.04  0.8527    0.2490  0.1082     0.9678                0.0322   \n",
       "2     0.03  0.8477    0.2167  0.0680     0.9711                0.0289   \n",
       "1     0.02  0.8432    0.1869  0.0311     0.9833                0.0167   \n",
       "0     0.01  0.8396    0.1658  0.0054     1.0000                0.0000   \n",
       "\n",
       "    false_pos_rate  error_rate  n_true_pos  n_false_pos  \n",
       "16          0.2711      0.4017      6519.0        593.0  \n",
       "15          0.2483      0.4203      6217.0        543.0  \n",
       "18          0.3251      0.3658      7124.0        711.0  \n",
       "17          0.3027      0.3815      6862.0        662.0  \n",
       "14          0.2199      0.4430      5847.0        481.0  \n",
       "13          0.1902      0.4660      5471.0        416.0  \n",
       "19          0.3557      0.3484      7428.0        778.0  \n",
       "12          0.1687      0.4885      5119.0        369.0  \n",
       "11          0.1395      0.5158      4684.0        305.0  \n",
       "10          0.1143      0.5418      4277.0        250.0  \n",
       "9           0.0983      0.5699      3861.0        215.0  \n",
       "8           0.0832      0.6022      3389.0        182.0  \n",
       "7           0.0704      0.6384      2871.0        154.0  \n",
       "6           0.0521      0.6657      2460.0        114.0  \n",
       "5           0.0375      0.6970      2004.0         82.0  \n",
       "4           0.0261      0.7248      1602.0         57.0  \n",
       "3           0.0187      0.7510      1231.0         41.0  \n",
       "2           0.0105      0.7833       774.0         23.0  \n",
       "1           0.0027      0.8131       354.0          6.0  \n",
       "0           0.0000      0.8342        61.0          0.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "store = pd.DataFrame([], columns=['weight',\n",
    "                                  'auc_PR',\n",
    "                                  'accuracy',\n",
    "                                  'recall',\n",
    "                                  'precision',\n",
    "                                  'false_discovery_rate',\n",
    "                                  'false_pos_rate',\n",
    "                                  'error_rate',\n",
    "                                  'n_true_pos',\n",
    "                                  'n_false_pos'])\n",
    "\n",
    "weights = [i/100 for i in range(1,21)]\n",
    "for weight in weights:\n",
    "    #Create random forest object\n",
    "    #scale_pos_weight = sum(negative) / sum(positive)\n",
    "    spw_tuning_model = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                                         scale_pos_weight = weight,\n",
    "                                         eval_matrix = 'aucpr',\n",
    "                                         seed = 0) #PR AUC - goal to minimze False positives \n",
    "\n",
    "    #Fit model with data\n",
    "    spw_tuning_model.fit(x_train, y_train)\n",
    "    \n",
    "    # ==================== Analyze ====================\n",
    "    model = spw_tuning_model\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, model.predict(x_test)).ravel()\n",
    "    store = store.append({'weight':weight,\n",
    "                          'auc_PR': round(average_precision_score(y_test, model.predict(x_test)),4),\n",
    "                          'accuracy': round((tp + tn) / (tp + tn + fn + fp),4),\n",
    "                          'recall': round(tp / (tp + fn),4),\n",
    "                          'precision': round(tp/(tp+fp),4),\n",
    "                          'false_discovery_rate': round(fp/(fp+tp),4),\n",
    "                          'false_pos_rate': round(fp / (tn + fp),4),\n",
    "                          'error_rate': round((fp + fn) / (tp + tn + fn + fp),4),\n",
    "                          'n_true_pos':tp,\n",
    "                          'n_false_pos':fp}, ignore_index=True)\n",
    "\n",
    "store = store.sort_values(by='auc_PR',ascending=False)\n",
    "store\n",
    "                     \n",
    "# # ==================== P-R Curve Plot ====================\n",
    "# model = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "#                           scale_pos_weight=store.weight.iloc[0],\n",
    "#                           eval_matrix = 'aucpr', \n",
    "#                           seed = 0)\n",
    "# model.fit(x_train, y_train)\n",
    "# y_pred = model.predict(x_test)\n",
    "# auc_PR = average_precision_score(y_test, y_pred)\n",
    "# precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "# plt.plot(recall, precision)\n",
    "# plt.xlabel('Recall (True Positive) ')\n",
    "# plt.ylabel('Precision (Proportion Correct)')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.title('Binary Precision-Recall curve: '\n",
    "#                    'auc_PR={0:0.2f}'.format(auc_PR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning Hyperparameters**\n",
    "- max_depth = depth of trees (3-10)\n",
    "- min_child_weight = similar to min_child_leaf for RandomForest\n",
    "- gamma = min. loss reduction required for split\n",
    "- subsample = frac of observations randomly sampled for tree (0.5-1)\n",
    "- colsample_bytree = number of features sampled for each tree\n",
    "- learning rate = typically between 0.01-0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "#Tune max_depth and min_child_weight\n",
    "param_test1 = {'max_depth':range(1,11,1),         #typically between 3-10\n",
    "               'min_child_weight':range(2,20,2)}  #default=1, arbitrarily selected\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                                                      seed = 0,\n",
    "                                                      early_stopping_rounds = 5,\n",
    "                                                      scale_pos_weight = store.weight.iloc[0]), \n",
    "                        param_grid = param_test1, \n",
    "                        scoring = 'average_precision',\n",
    "                        n_jobs = -1,\n",
    "                        iid = False, #returns avg score across folds\n",
    "                        cv = 5)\n",
    "\n",
    "gsearch1.fit(x_train,y_train)\n",
    "print(gsearch1.best_params_) #best parameters from CV\n",
    "print(gsearch1.best_score_)  #best score from CV\n",
    "\n",
    "# Enter tuned parameters into new model\n",
    "xgb1 = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                         seed = 0,\n",
    "                         early_stopping_rounds = 5,\n",
    "                         n_jobs = -1,\n",
    "                         eval_matrix = 'aucpr',\n",
    "                         scale_pos_weight = store.weight.iloc[0], \n",
    "                         max_depth = gsearch1.best_params_['max_depth'],\n",
    "                         min_child_weight = gsearch1.best_params_['min_child_weight'])\n",
    "\n",
    "# modelfit(xgb1, train, train_X)\n",
    "xgb1.fit(x_train, y_train)\n",
    "\n",
    "# ==================== Analyze ====================\n",
    "model = xgb1\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, model.predict(x_test)).ravel()\n",
    "xgb1_results = {'max_depth': gsearch1.best_params_['max_depth'],\n",
    "                'min_child_weight': gsearch1.best_params_['min_child_weight'],\n",
    "                'auc_PR': round(average_precision_score(y_test, model.predict(x_test)),4),\n",
    "                'accuracy': round((tp + tn) / (tp + tn + fn + fp),4),\n",
    "                'recall': round(tp / (tp + fn),4),\n",
    "                'precision': round(tp/(tp+fp),4),\n",
    "                'false_discovery_rate': round(fp/(fp+tp),4),\n",
    "                'false_pos_rate': round(fp / (tn + fp),4),\n",
    "                'error_rate': round((fp + fn) / (tp + tn + fn + fp),4),\n",
    "                'n_true_pos':tp,\n",
    "                'n_false_pos':fp}\n",
    "\n",
    "xgb1_results\n",
    "                     \n",
    "# # ==================== P-R Curve Plot ====================\n",
    "# model.fit(x_train, y_train)\n",
    "# y_pred = model.predict(x_test)\n",
    "# auc_PR = average_precision_score(y_test, y_pred)\n",
    "# precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "# plt.plot(recall, precision)\n",
    "# plt.xlabel('Recall (True Positive) ')\n",
    "# plt.ylabel('Precision (Proportion Correct)')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.title('Binary Precision-Recall curve: '\n",
    "#                    'auc_PR={0:0.2f}'.format(auc_PR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.0}\n",
      "0.9234427058309368\n",
      "CPU times: user 20.6 s, sys: 99.2 ms, total: 20.7 s\n",
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.0,\n",
       " 'auc_PR': 0.8395,\n",
       " 'accuracy': 0.165,\n",
       " 'recall': 0.0045,\n",
       " 'precision': 1.0,\n",
       " 'false_discovery_rate': 0.0,\n",
       " 'false_pos_rate': 0.0,\n",
       " 'error_rate': 0.835,\n",
       " 'n_true_pos': 51,\n",
       " 'n_false_pos': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "#Tune gamma\n",
    "param_test2 = {'gamma':[i/10 for i in range(0,5)]}  #default=1, arbitrarily selected\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                                                      seed = 0,\n",
    "                                                      early_stopping_rounds = 5,\n",
    "                                                      scale_pos_weight = store.weight.iloc[0],\n",
    "                                                      max_depth = gsearch1.best_params_['max_depth'],\n",
    "                                                      min_child_weight = gsearch1.best_params_['min_child_weight']), \n",
    "                        param_grid = param_test2, \n",
    "                        scoring = 'average_precision',\n",
    "                        n_jobs = -1,\n",
    "                        iid = False, #returns avg score across folds\n",
    "                        cv = 5)\n",
    "\n",
    "gsearch2.fit(x_train,y_train)\n",
    "print(gsearch2.best_params_) #best parameters from CV\n",
    "print(gsearch2.best_score_)  #best score from CV\n",
    "\n",
    "# Enter tuned parameters into new model\n",
    "xgb2 = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                         seed = 0,\n",
    "                         early_stopping_rounds = 5,\n",
    "                         n_jobs = -1,\n",
    "                         eval_matrix = 'aucpr',\n",
    "                         scale_pos_weight = store.weight.iloc[0],\n",
    "                         max_depth = gsearch1.best_params_['max_depth'],\n",
    "                         min_child_weight = gsearch1.best_params_['min_child_weight'],\n",
    "                         gamma = gsearch2.best_params_['gamma'])\n",
    "\n",
    "# modelfit(xgb1, train, train_X)\n",
    "xgb2.fit(x_train, y_train)\n",
    "\n",
    "# ==================== Analyze ====================\n",
    "model = xgb2\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, model.predict(x_test)).ravel()\n",
    "xgb2_results = {'gamma': gsearch2.best_params_['gamma'],\n",
    "                'auc_PR': round(average_precision_score(y_test, model.predict(x_test)),4),\n",
    "                'accuracy': round((tp + tn) / (tp + tn + fn + fp),4),\n",
    "                'recall': round(tp / (tp + fn),4),\n",
    "                'precision': round(tp/(tp+fp),4),\n",
    "                'false_discovery_rate': round(fp/(fp+tp),4),\n",
    "                'false_pos_rate': round(fp / (tn + fp),4),\n",
    "                'error_rate': round((fp + fn) / (tp + tn + fn + fp),4),\n",
    "                'n_true_pos':tp,\n",
    "                'n_false_pos':fp}\n",
    "\n",
    "xgb2_results\n",
    "                     \n",
    "# # ==================== P-R Curve Plot ====================\n",
    "# model.fit(x_train, y_train)\n",
    "# y_pred = model.predict(x_test)\n",
    "# auc_PR = average_precision_score(y_test, y_pred)\n",
    "# precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "# plt.plot(recall, precision)\n",
    "# plt.xlabel('Recall (True Positive) ')\n",
    "# plt.ylabel('Precision (Proportion Correct)')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.title('Binary Precision-Recall curve: '\n",
    "#                    'auc_PR={0:0.2f}'.format(auc_PR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9, 'subsample': 0.8}\n",
      "0.923660932808018\n",
      "CPU times: user 21 s, sys: 690 ms, total: 21.7 s\n",
      "Wall time: 6min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.8,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'auc_PR': 0.8394,\n",
       " 'accuracy': 0.1648,\n",
       " 'recall': 0.0042,\n",
       " 'precision': 1.0,\n",
       " 'false_discovery_rate': 0.0,\n",
       " 'false_pos_rate': 0.0,\n",
       " 'error_rate': 0.8352,\n",
       " 'n_true_pos': 48,\n",
       " 'n_false_pos': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "#Tune subsample and colsample_bytree parameters\n",
    "param_test3 = {'subsample':[i/10 for i in range(1,10)],\n",
    "               'colsample_bytree':[i/10 for i in range(5,15)]}\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                                                      seed = 0,\n",
    "                                                      early_stopping_rounds = 5,\n",
    "                                                      scale_pos_weight = store.weight.iloc[0],\n",
    "                                                      max_depth = gsearch1.best_params_['max_depth'],\n",
    "                                                      min_child_weight = gsearch1.best_params_['min_child_weight'],\n",
    "                                                      gamma = gsearch2.best_params_['gamma']), \n",
    "                        param_grid = param_test3, \n",
    "                        scoring = 'average_precision',\n",
    "                        n_jobs = -1,\n",
    "                        iid = False, #returns avg score across folds\n",
    "                        cv = 5)\n",
    "\n",
    "gsearch3.fit(x_train,y_train)\n",
    "print(gsearch3.best_params_) #best parameters from CV\n",
    "print(gsearch3.best_score_)  #best score from CV\n",
    "\n",
    "# Enter tuned parameters into new model\n",
    "xgb3 = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                         seed = 0,\n",
    "                         early_stopping_rounds = 5,\n",
    "                         n_jobs = -1,\n",
    "                         eval_matrix = 'aucpr',\n",
    "                         scale_pos_weight = store.weight.iloc[0],\n",
    "                         max_depth = gsearch1.best_params_['max_depth'],\n",
    "                         min_child_weight = gsearch1.best_params_['min_child_weight'],\n",
    "                         gamma = gsearch2.best_params_['gamma'],\n",
    "                         subsample = gsearch3.best_params_['subsample'], \n",
    "                         colsample_bytree = gsearch3.best_params_['colsample_bytree'])\n",
    "\n",
    "# modelfit(xgb1, train, train_X)\n",
    "xgb3.fit(x_train, y_train)\n",
    "\n",
    "# ==================== Analyze ====================\n",
    "model = xgb3\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, model.predict(x_test)).ravel()\n",
    "xgb3_results = {'subsample': gsearch3.best_params_['subsample'],\n",
    "                'colsample_bytree': gsearch3.best_params_['colsample_bytree'],\n",
    "                'auc_PR': round(average_precision_score(y_test, model.predict(x_test)),4),\n",
    "                'accuracy': round((tp + tn) / (tp + tn + fn + fp),4),\n",
    "                'recall': round(tp / (tp + fn),4),\n",
    "                'precision': round(tp/(tp+fp),4),\n",
    "                'false_discovery_rate': round(fp/(fp+tp),4),\n",
    "                'false_pos_rate': round(fp / (tn + fp),4),\n",
    "                'error_rate': round((fp + fn) / (tp + tn + fn + fp),4),\n",
    "                'n_true_pos':tp,\n",
    "                'n_false_pos':fp}\n",
    "\n",
    "xgb3_results\n",
    "                     \n",
    "# # ==================== P-R Curve Plot ====================\n",
    "# model.fit(x_train, y_train)\n",
    "# y_pred = model.predict(x_test)\n",
    "# auc_PR = average_precision_score(y_test, y_pred)\n",
    "# precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "# plt.plot(recall, precision)\n",
    "# plt.xlabel('Recall (True Positive) ')\n",
    "# plt.ylabel('Precision (Proportion Correct)')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.title('Binary Precision-Recall curve: '\n",
    "#                    'auc_PR={0:0.2f}'.format(auc_PR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.055}\n",
      "0.922752756010724\n",
      "CPU times: user 18.5 s, sys: 128 ms, total: 18.6 s\n",
      "Wall time: 1min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.055,\n",
       " 'auc_PR': 0.8387,\n",
       " 'accuracy': 0.1613,\n",
       " 'recall': 0.0,\n",
       " 'precision': nan,\n",
       " 'false_discovery_rate': nan,\n",
       " 'false_pos_rate': 0.0,\n",
       " 'error_rate': 0.8387,\n",
       " 'n_true_pos': 0,\n",
       " 'n_false_pos': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "#Tune subsample and colsample_bytree parameters\n",
    "param_test4 = {'learning_rate':[i/1000 for i in range(10,60,5)]}\n",
    "\n",
    "gsearch4 = GridSearchCV(estimator = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                                                      seed = 0,\n",
    "                                                      early_stopping_rounds = 5,\n",
    "                                                      scale_pos_weight = store.weight.iloc[0],\n",
    "                                                      max_depth = gsearch1.best_params_['max_depth'],\n",
    "                                                      min_child_weight = gsearch1.best_params_['min_child_weight'],\n",
    "                                                      gamma = gsearch2.best_params_['gamma'],\n",
    "                                                      subsample = gsearch3.best_params_['subsample'],\n",
    "                                                      colsample_bytree = gsearch3.best_params_['colsample_bytree']), \n",
    "                        param_grid = param_test4, \n",
    "                        scoring = 'average_precision',\n",
    "                        n_jobs = -1,\n",
    "                        iid = False, #returns avg score across folds\n",
    "                        cv = 5)\n",
    "\n",
    "gsearch4.fit(x_train,y_train)\n",
    "print(gsearch4.best_params_) #best parameters from CV\n",
    "print(gsearch4.best_score_)  #best score from CV\n",
    "\n",
    "# Enter tuned parameters into new model\n",
    "xgb4 = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                         seed = 0,\n",
    "                         early_stopping_rounds = 5,\n",
    "                         n_jobs = -1,\n",
    "                         eval_matrix = 'aucpr',\n",
    "                         scale_pos_weight = store.weight.iloc[0],\n",
    "                         max_depth = gsearch1.best_params_['max_depth'],\n",
    "                         min_child_weight = gsearch1.best_params_['min_child_weight'],\n",
    "                         gamma = gsearch2.best_params_['gamma'],\n",
    "                         subsample = gsearch3.best_params_['subsample'], \n",
    "                         colsample_bytree = gsearch3.best_params_['colsample_bytree'],\n",
    "                         learning_rate = gsearch4.best_params_['learning_rate'])\n",
    "\n",
    "# modelfit(xgb1, train, train_X)\n",
    "xgb4.fit(x_train, y_train)\n",
    "\n",
    "# ==================== Analyze ====================\n",
    "model = xgb4\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, model.predict(x_test)).ravel()\n",
    "xgb4_results = {'learning_rate': gsearch4.best_params_['learning_rate'],\n",
    "                'auc_PR': round(average_precision_score(y_test, model.predict(x_test)),4),\n",
    "                'accuracy': round((tp + tn) / (tp + tn + fn + fp),4),\n",
    "                'recall': round(tp / (tp + fn),4),\n",
    "                'precision': round(tp/(tp+fp),4),\n",
    "                'false_discovery_rate': round(fp/(fp+tp),4),\n",
    "                'false_pos_rate': round(fp / (tn + fp),4),\n",
    "                'error_rate': round((fp + fn) / (tp + tn + fn + fp),4),\n",
    "                'n_true_pos':tp,\n",
    "                'n_false_pos':fp}\n",
    "\n",
    "xgb4_results\n",
    "                     \n",
    "# # ==================== P-R Curve Plot ====================\n",
    "# model.fit(x_train, y_train)\n",
    "# y_pred = model.predict(x_test)\n",
    "# auc_PR = average_precision_score(y_test, y_pred)\n",
    "# precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "# plt.plot(recall, precision)\n",
    "# plt.xlabel('Recall (True Positive) ')\n",
    "# plt.ylabel('Precision (Proportion Correct)')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.title('Binary Precision-Recall curve: '\n",
    "#                    'auc_PR={0:0.2f}'.format(auc_PR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "#Tune subsample and colsample_bytree parameters\n",
    "param_test5 = {'n_estimators':range(100,1100,100)}\n",
    "\n",
    "gsearch5 = GridSearchCV(estimator = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                                                      seed = 0,\n",
    "                                                      early_stopping_rounds = 5,\n",
    "                                                      scale_pos_weight = store.weight.iloc[0],\n",
    "                                                      max_depth = gsearch1.best_params_['max_depth'],\n",
    "                                                      min_child_weight = gsearch1.best_params_['min_child_weight'],\n",
    "                                                      gamma = gsearch2.best_params_['gamma'],\n",
    "                                                      subsample = gsearch3.best_params_['subsample'],\n",
    "                                                      colsample_bytree = gsearch3.best_params_['colsample_bytree'], \n",
    "                                                      learning_rate = gsearch4.best_params_['learning_rate']), \n",
    "                        param_grid = param_test5, \n",
    "                        scoring = 'average_precision',\n",
    "                        n_jobs = -1,\n",
    "                        iid = False, #returns avg score across folds\n",
    "                        cv = 5)\n",
    "\n",
    "gsearch5.fit(x_train,y_train)\n",
    "print(gsearch5.best_params_) #best parameters from CV\n",
    "print(gsearch5.best_score_)  #best score from CV\n",
    "\n",
    "# Enter tuned parameters into new model\n",
    "xgb5 = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                         seed = 0,\n",
    "                         early_stopping_rounds = 5,\n",
    "                         n_jobs = -1,\n",
    "                         eval_matrix = 'aucpr',\n",
    "                         scale_pos_weight = store.weight.iloc[0],\n",
    "                         max_depth = gsearch1.best_params_['max_depth'],\n",
    "                         min_child_weight = gsearch1.best_params_['min_child_weight'],\n",
    "                         gamma = gsearch2.best_params_['gamma'],\n",
    "                         subsample = gsearch3.best_params_['subsample'], \n",
    "                         colsample_bytree = gsearch3.best_params_['colsample_bytree'],\n",
    "                         learning_rate = gsearch4.best_params_['learning_rate'], \n",
    "                         n_estimators=gsearch5.best_params_['n_estimators'])\n",
    "\n",
    "# modelfit(xgb1, train, train_X)\n",
    "xgb5.fit(x_train, y_train)\n",
    "\n",
    "# ==================== Analyze ====================\n",
    "model = xgb5\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, model.predict(x_test)).ravel()\n",
    "xgb5_results = {'n_estimators': gsearch4.best_params_['n_estimators'],\n",
    "                'auc_PR': round(average_precision_score(y_test, model.predict(x_test)),4),\n",
    "                'accuracy': round((tp + tn) / (tp + tn + fn + fp),4),\n",
    "                'recall': round(tp / (tp + fn),4),\n",
    "                'precision': round(tp/(tp+fp),4),\n",
    "                'false_discovery_rate': round(fp/(fp+tp),4),\n",
    "                'false_pos_rate': round(fp / (tn + fp),4),\n",
    "                'error_rate': round((fp + fn) / (tp + tn + fn + fp),4),\n",
    "                'n_true_pos':tp,\n",
    "                'n_false_pos':fp}\n",
    "\n",
    "xgb5_results\n",
    "                     \n",
    "# # ==================== P-R Curve Plot ====================\n",
    "# model.fit(x_train, y_train)\n",
    "# y_pred = model.predict(x_test)\n",
    "# auc_PR = average_precision_score(y_test, y_pred)\n",
    "# precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "# plt.plot(recall, precision)\n",
    "# plt.xlabel('Recall (True Positive) ')\n",
    "# plt.ylabel('Precision (Proportion Correct)')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.title('Binary Precision-Recall curve: '\n",
    "#                    'auc_PR={0:0.2f}'.format(auc_PR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate  :  83.82\n",
      "Accuracy  :  16.18\n",
      "Sensitivity  :  0.0\n",
      "Specificity  :  100.0\n",
      "False positive rate  :  0.0\n"
     ]
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, xgb_final.predict(x_train)).ravel()\n",
    "\n",
    "#Calculate metrics\n",
    "accuracy = round((tp + tn) / (tp + tn + fn + fp),4) * 100\n",
    "print(\"Accuracy: {0}% of loans were correctly identified\\n\".format(accuracy))\n",
    "\n",
    "specificity = round(tn / (tn + fp),4) * 100 #true negative rate\n",
    "print(\"Specificity: {0}% of loans with ROI<-20% were identified as a bad loan loan\\n\".format(sensitivity))\n",
    "\n",
    "recall = round(tp / (tp + fn), 4) * 100 #true positive rate\n",
    "print(\"Recall/Sensitivity: {0}% of loans with ROI>-20% were identified as a good loan\\n\".format(recall))\n",
    "\n",
    "precision = round(tp/(tp+fp),4) * 100\n",
    "print(\"Precision: {0}% of loans identified as a good loan (ROI>-20%) were correct\\n\".format(precision))\n",
    "\n",
    "false_discovery_rate = round(fp/(fp+tp),4) * 100\n",
    "print(\"False discovery rate: {0}% of loans identified as good [ROI>-20%] were actually bad loans [ROI<-20%]\\n\".format(false_discover_rate))\n",
    "\n",
    "false_pos_rate = round(fp / (tn + fp),4) * 100\n",
    "print(\"False Positive Rate: {0}% of bad loans [ROI<-20%] were identified as a good loan [ROI>-20%]\\n\".format(false_pos_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1a20f15f90>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(spw_tuning_model,\n",
    "                      x_test,\n",
    "                      y_test,\n",
    "                      cmap=plt.cm.Blues )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_wrapper(refit_score='precision_score'):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifier using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    grid_search = GridSearchCV(model,\n",
    "                                     param_grid,\n",
    "                                     scoring=scorers,\n",
    "                                     refit=refit_score,\n",
    "                                     cv=skf,\n",
    "#                                      random_state=42,\n",
    "#                                      n_iter=100,\n",
    "                                     verbose=1,\n",
    "                                     return_train_score=True,\n",
    "                                     n_jobs = -1)\n",
    "    \n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # make the predictions\n",
    "    y_pred = grid_search.predict(x_test)\n",
    "\n",
    "    print('Best params for {}'.format(refit_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # confusion matrix on the test data.\n",
    "    print('\\nConfusion matrix of XGBoost optimized for {} on the test data:'.format(refit_score))\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    precision = round(tp/(tp+fp),4) * 100\n",
    "    print(\"\\nPrecision: {0}% of loans identified as a good loan (ROI>-20%) were correct\\n\".format(precision))\n",
    "\n",
    "    false_discovery_rate = round(fp/(fp+tp),4) * 100\n",
    "    print(\"False discovery rate: {0}% of loans identified as good [ROI>-20%] were actually bad loans [ROI<-20%]\\n\\n\".format(false_discover_rate))\n",
    "\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4050000 candidates, totalling 20250000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-d648f7b6ef68>\u001b[0m in \u001b[0;36mgrid_search_wrapper\u001b[0;34m(refit_score)\u001b[0m\n\u001b[1;32m     17\u001b[0m                                      n_jobs = -1)\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# make the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    853\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0mdelete_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 \u001b[0mqmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0mcq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Based on link: https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                              early_stopping_rounds = 5,\n",
    "                              scale_pos_weight = (len(y)-y.sum())/y.sum())\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'subsample':[i/10 for i in range(5,15)],\n",
    "    'colsample_bytree':[i/10 for i in range(5,15)],\n",
    "    'max_depth':range(1,11,1),\n",
    "    'min_child_weight':range(3,11,2),\n",
    "    'n_estimators':range(100,1100,200)\n",
    "}\n",
    "\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "}\n",
    "\n",
    "grid_search_model = grid_search_wrapper(refit_score='precision_score')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
