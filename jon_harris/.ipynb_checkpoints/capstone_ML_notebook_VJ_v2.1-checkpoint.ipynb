{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Club: Machine Learning Capstone Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from time import strptime  # format data columns\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # ignore warnings throughout notebook\n",
    "pd.set_option(\"display.max_columns\", None)  # show all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "filepath = \"./data/accepted_subsampled_5percent.csv\" #will be personalized\n",
    "df = pd.read_csv(filepath, sep=\",\")\n",
    "\n",
    "df_cleaned = df.copy() #work from second copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features known to investors based on LC website\n",
    "known_vars = ['acc_now_delinq',             # accounts now deliquent\n",
    "              'collections_12_mths_ex_med', # collections excluding medical\n",
    "              'fico_range_high',            # credit score range\n",
    "              'fico_range_low',             # creit score range\n",
    "              'delinq_2yrs',                # delinquencies in last two years\n",
    "              'delinq_amnt',                # delinquency amount\n",
    "              'earliest_cr_line',           # earliest credit line\n",
    "              'home_ownership',             # home ownership\n",
    "              'dti',                        # debt2income ratio\n",
    "              'annual_inc',                 # annual income\n",
    "              'initial_list_status',        # initial listing status\n",
    "              'inq_last_6mths',             # credit inquires in last 6mo\n",
    "              'int_rate',                   # interest rate\n",
    "              'verification_status_joint',  # is this a joint app\n",
    "              'emp_length',                 # length of employment (yr)\n",
    "              'loan_amnt',                  # loan amount\n",
    "              'id',                         # loan id\n",
    "              'purpose',                    # purpose of the loan\n",
    "              'term',                       # loan term (3 or 5yr)\n",
    "              'addr_state',                 # borrower location state\n",
    "              'installment',                # montly payment\n",
    "              'mths_since_last_delinq',     # mo since last delinquency\n",
    "              'mths_since_last_major_derog',# mo since last maj. derogatory\n",
    "              'mths_since_last_record',     # mo since last public record\n",
    "              'open_acc',                   # open credit line\n",
    "              'pub_rec',                    # public records on file\n",
    "              'revol_util',                 # revolving balance utilization (%)\n",
    "              'revol_bal',                  # revolving credit balance ($)\n",
    "              'tot_coll_amt',               # total collection amount ever\n",
    "              'total_acc',                  # total credit lines\n",
    "              'tot_cur_bal',                # total current balance\n",
    "              'verification_status',        # verified income (Y/N I think)\n",
    "              'grade'                       # loan grade\n",
    "             ]\n",
    "\n",
    "# Sanity check, print variable if not found within original dataframe\n",
    "# [ print(var) for var in known_vars if (var not in df.columns)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Missing Data of Known Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verification_status_joint      0.949313\n",
       "mths_since_last_record         0.838543\n",
       "mths_since_last_major_derog    0.744395\n",
       "mths_since_last_delinq         0.513786\n",
       "emp_length                     0.063868\n",
       "tot_cur_bal                    0.033430\n",
       "tot_coll_amt                   0.033430\n",
       "revol_util                     0.001006\n",
       "dti                            0.000829\n",
       "collections_12_mths_ex_med     0.000476\n",
       "open_acc                       0.000185\n",
       "pub_rec                        0.000185\n",
       "total_acc                      0.000185\n",
       "inq_last_6mths                 0.000185\n",
       "earliest_cr_line               0.000185\n",
       "delinq_amnt                    0.000185\n",
       "delinq_2yrs                    0.000185\n",
       "acc_now_delinq                 0.000185\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assess missingness of known variables\n",
    "missingness = df_cleaned[known_vars].isnull().mean().T\n",
    "missingness = missingness.loc[missingness>0].sort_values(ascending=False)\n",
    "missingness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop features missing > 50% \n",
    "feat_wManyMissing = missingness.index[np.where(missingness > .5)].to_list()\n",
    "df_cleaned[known_vars].drop(df_cleaned[feat_wManyMissing], axis=1, inplace=True)\n",
    "[known_vars.remove(var) for var in feat_wManyMissing] #remove features from known_var list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace NA's of numeric 'known_var' features with mean value\n",
    "numeric_var = ['tot_cur_bal',\n",
    "               'tot_coll_amt',\n",
    "               'revol_util',\n",
    "               'collections_12_mths_ex_med',\n",
    "               'open_acc',\n",
    "               'pub_rec',\n",
    "               'total_acc',\n",
    "               'inq_last_6mths',\n",
    "               'delinq_amnt',\n",
    "               'delinq_2yrs',\n",
    "               'dti' ]\n",
    "\n",
    "# List comprehension through numerica variables\n",
    "[df_cleaned[var].fillna(df[var].mean(), inplace=True) for var in numeric_var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper function to replace missing character strings with randomly selected value\n",
    "def fillna_random(var):\n",
    "    #find index of missing values\n",
    "    miss_idx = df_cleaned.loc[ df_cleaned[var].isnull()].index.tolist()\n",
    "    \n",
    "    #find new values to replace NaN values\n",
    "    new_val = df_cleaned[var].loc[~df_cleaned.index.isin(miss_idx)].sample(len(miss_idx)).values.tolist()\n",
    "\n",
    "    #replace values\n",
    "    df_cleaned[var][miss_idx] = new_val\n",
    "\n",
    "# ==================================================\n",
    "# Replace NA's of character 'known_var' features with random\n",
    "non_numeric_var = ['emp_length', 'earliest_cr_line', 'acc_now_delinq', 'delinq_2yrs'] #list of non-numeric variables\n",
    "[fillna_random(var) for var in non_numeric_var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc_now_delinq                0\n",
       "collections_12_mths_ex_med    0\n",
       "fico_range_high               0\n",
       "fico_range_low                0\n",
       "delinq_2yrs                   0\n",
       "delinq_amnt                   0\n",
       "earliest_cr_line              0\n",
       "home_ownership                0\n",
       "dti                           0\n",
       "annual_inc                    0\n",
       "initial_list_status           0\n",
       "inq_last_6mths                0\n",
       "int_rate                      0\n",
       "emp_length                    0\n",
       "loan_amnt                     0\n",
       "id                            0\n",
       "purpose                       0\n",
       "term                          0\n",
       "addr_state                    0\n",
       "installment                   0\n",
       "open_acc                      0\n",
       "pub_rec                       0\n",
       "revol_util                    0\n",
       "revol_bal                     0\n",
       "tot_coll_amt                  0\n",
       "total_acc                     0\n",
       "tot_cur_bal                   0\n",
       "verification_status           0\n",
       "grade                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check that no more missing values\n",
    "df_cleaned[known_vars].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'C', 'A', 'E', 'D', 'F', 'G'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['grade'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify loan status (non-FullyPaid or ChargedOff loans will be converted to NAN)\n",
    "df_cleaned['loan_status'] = df_cleaned['loan_status'].map({'Fully Paid':'Fully Paid',\n",
    "                                                           'Charged Off':'Charged Off',\n",
    "                                                           'Does not meet the credit policy. Status:Fully Paid': 'Fully Paid',\n",
    "                                                           'Does not meet the credit policy. Status:Charged Off': 'Charged Off'})\n",
    "\n",
    "# Remove non-completed loans\n",
    "df_cleaned.drop(df_cleaned.loc[df_cleaned['loan_status'].isnull()].index.tolist(), axis=0, inplace=True)\n",
    "\n",
    "# Simplify home ownership\n",
    "df_cleaned['home_ownership'] = df_cleaned['home_ownership'].map({'MORTGAGE':'mortgage',\n",
    "                                                                 'OWN':'own',\n",
    "                                                                 'RENT':'rent'})\n",
    "\n",
    "# Remove 25 observations without houses\n",
    "df_cleaned.drop(df_cleaned.loc[df_cleaned['home_ownership'].isnull()].index.tolist(), axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Reformat date features and calculate features related to prepayment  \n",
    "df_cleaned['term_year'] = np.where(df_cleaned['term']==' 36 months', 3,5)\n",
    "df_cleaned['earliest_cr_line'] =  pd.to_datetime(df_cleaned['earliest_cr_line'])\n",
    "df_cleaned['issue_date'] =  pd.to_datetime(df_cleaned['issue_d'])\n",
    "df_cleaned['last_pymnt_date'] = pd.to_datetime(df_cleaned['last_pymnt_d'])\n",
    "df_cleaned['exp_last_pymnt_date'] = pd.to_datetime(df_cleaned['issue_d'].str[0:3]\n",
    "                                                   +'-'\n",
    "                                                   + (df_cleaned['issue_d'].str[-4:].astype('int')\n",
    "                                                   + df_cleaned['term_year']).astype('str'))\n",
    "\n",
    "# Calculate credit history ( in months )\n",
    "date_ofloan = df_cleaned['issue_date'].dt.to_period('M').astype(int)\n",
    "date_credline = df_cleaned['earliest_cr_line'].dt.to_period('M').astype(int)\n",
    "df_cleaned['credit_hist_mths'] = date_ofloan - date_credline\n",
    "\n",
    "# Log-transform skewed continuous features\n",
    "df_cleaned['delinq_amnt_log'] = df_cleaned['delinq_amnt'].add(1).apply(np.log)\n",
    "df_cleaned['annual_inc_log'] = df_cleaned['annual_inc'].add(1).apply(np.log)\n",
    "df_cleaned['dti_log'] = df_cleaned['dti'].add(1).apply(np.log)\n",
    "df_cleaned['funded_amnt_log'] = df_cleaned['funded_amnt'].add(1).apply(np.log)\n",
    "df_cleaned['tot_coll_amt_log'] = df_cleaned['tot_coll_amt'].add(1).apply(np.log)\n",
    "df_cleaned['tot_cur_bal_log'] = df_cleaned['tot_cur_bal'].add(1).apply(np.log)\n",
    "df_cleaned['total_acc_log'] = df_cleaned['total_acc'].add(1).apply(np.log)\n",
    "df_cleaned['revol_bal_log'] = df_cleaned['revol_bal'].add(1).apply(np.log)\n",
    "df_cleaned['installment_log'] = df_cleaned['installment'].add(1).apply(np.log)\n",
    "df_cleaned['open_acc_log'] = df_cleaned['open_acc'].add(1).apply(np.log)\n",
    "\n",
    "# Simplify loan purpose - debt consolidation, credit card, and other\n",
    "df_cleaned['purpose'] = df_cleaned['purpose'].map({'debt_consolidation':'debt_consolidation',\n",
    "                                                   'credit_card':'credit_card'})\n",
    "df_cleaned['purpose'].fillna('other',inplace=True)\n",
    "\n",
    "# Convert loan grade to ordinal feature\n",
    "df_cleaned['grade'] = df_cleaned['grade'].map({'A':1,\n",
    "                                               'B':2,\n",
    "                                               'C':3,\n",
    "                                               'D':4,\n",
    "                                               'E':5,\n",
    "                                               'F':6,\n",
    "                                               'G':7})\n",
    "\n",
    "# Simplify employment length to four categories\n",
    "df_cleaned['emp_length'] = df_cleaned['emp_length'].map({'< 1 year':0.5,\n",
    "                                                         '1 year':1,\n",
    "                                                         '2 years':2,\n",
    "                                                         '3 years':3,\n",
    "                                                         '4 years':4,\n",
    "                                                         '5 years':5,\n",
    "                                                         '6 years':6,\n",
    "                                                         '7 years':7,\n",
    "                                                         '8 years':8,\n",
    "                                                         '9 years':9,\n",
    "                                                         '10+ years':10})\n",
    "\n",
    "# Create new binary features\n",
    "df_cleaned['has_pub_rec'] = np.where(df_cleaned['pub_rec']>0,1,0) #0-=no public record\n",
    "df_cleaned['has_paid_early'] = np.where((df_cleaned.loan_status=='Fully Paid')&(df_cleaned.last_pymnt_date < df_cleaned.exp_last_pymnt_date), 1, 0)\n",
    "df_cleaned['has_36mo_loan'] = np.where(df_cleaned['term'].str.contains('36'),1,0) #0=60mo loan\n",
    "df_cleaned['has_delinq_now'] = np.where(df_cleaned['acc_now_delinq']>0, 1, 0)\n",
    "df_cleaned['has_delinq_past2yrs'] = np.where(df_cleaned['delinq_2yrs']>0, 1, 0) #0=no delinq within 2yrs\n",
    "df_cleaned['has_whole_liststatus'] = np.where(df_cleaned['initial_list_status']=='w', 1, 0) #0=f\n",
    "df_cleaned['has_fullypaid'] = np.where(df_cleaned['loan_status']=='Fully Paid', 1, 0) #0=charged off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create response variable based on \n",
    "threshold = 10 #goal of loans is loss of <10%\n",
    "df_cleaned[\"roi_perc\"] = df_cleaned[\"total_pymnt\"].div(df_cleaned[\"funded_amnt\"]).sub(1).mul(100)\n",
    "df_cleaned['roi_response'] = np.where(df_cleaned['roi_perc'] > threshold, 1, 0) #84% of all loans > -20% ROI\n",
    "\n",
    "df_cleaned['roi_response_5'] = np.where(df_cleaned['roi_perc'] > 5, 1, 0)\n",
    "df_cleaned['credit_hist_mths'] = np.where(df_cleaned['credit_hist_mths'] < 0, 0, df_cleaned['credit_hist_mths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate list of predictor variables to be used for ML\n",
    "predictor_vars = ['annual_inc_log',\n",
    "                  'credit_hist_mths',\n",
    "                  'delinq_amnt_log',\n",
    "                  'dti_log',\n",
    "                  'emp_length',\n",
    "                  'fico_range_high',\n",
    "                  'funded_amnt_log',\n",
    "                  'grade',\n",
    "                  'has_36mo_loan',\n",
    "                  'has_delinq_now',\n",
    "                  'has_delinq_past2yrs',\n",
    "                  'has_fullypaid',\n",
    "                  'has_paid_early',\n",
    "                  'has_pub_rec',\n",
    "                  'has_whole_liststatus',\n",
    "                  'home_ownership',\n",
    "                  'inq_last_6mths',\n",
    "                  'installment_log',\n",
    "                  'int_rate',\n",
    "                  'open_acc_log',\n",
    "                  'purpose',\n",
    "                  'revol_bal_log',\n",
    "                  'revol_util',\n",
    "                  'tot_coll_amt_log',\n",
    "                  'tot_cur_bal_log',\n",
    "                  'total_acc_log',\n",
    "                  'verification_status']\n",
    "\n",
    "response_var = 'roi_response'\n",
    "response_var_5 = 'roi_response_5'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "- Goal is to build classifier that predicts if loan results in desirable outcome\n",
    "- Should also report feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify categorical features\n",
    "home_ownership_dummy = pd.get_dummies(df_cleaned['home_ownership'],\n",
    "                                      prefix=\"home_ownership\").drop('home_ownership_mortgage',axis=1)\n",
    "\n",
    "purpose_dummy = pd.get_dummies(df_cleaned['purpose'],\n",
    "                               prefix=\"purpose\").drop('purpose_debt_consolidation',axis=1)\n",
    "\n",
    "verification_status_dummy = pd.get_dummies(df_cleaned['verification_status'],\n",
    "                               prefix=\"verification_status\").drop('verification_status_Source Verified',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numeric features in the final dataframe\n",
    "numeric_vars = ['annual_inc_log',\n",
    "                'credit_hist_mths',\n",
    "                'delinq_amnt_log',\n",
    "                'dti_log',\n",
    "                'emp_length',\n",
    "                'fico_range_high',\n",
    "                'funded_amnt_log',\n",
    "                'grade',\n",
    "                'has_36mo_loan',\n",
    "                'has_delinq_now',\n",
    "                'has_delinq_past2yrs',\n",
    "                'has_pub_rec',\n",
    "                'has_whole_liststatus',\n",
    "                'inq_last_6mths',\n",
    "                'installment_log',\n",
    "                'int_rate',\n",
    "                'open_acc_log',\n",
    "                'revol_bal_log',\n",
    "                'revol_util',\n",
    "                'tot_coll_amt_log',\n",
    "                'tot_cur_bal_log',\n",
    "                'total_acc_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataframe for model consumption\n",
    "\n",
    "df_feature_final = pd.concat([df_cleaned[numeric_vars],\n",
    "                      home_ownership_dummy,\n",
    "                      purpose_dummy,\n",
    "                      verification_status_dummy],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize final dataframe\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_feature_final)\n",
    "df_feature_final_scaled = pd.DataFrame(scaler.transform(df_feature_final))\n",
    "df_feature_final_scaled.columns = df_feature_final.columns\n",
    "df_feature_final_scaled.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reset index because feature index changed\n",
    "class_response = df_cleaned[response_var].reset_index().drop('index',axis=1)\n",
    "class_response_5 = df_cleaned[response_var_5].reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model based on 10% threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.667351\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           roi_response   No. Observations:                67805\n",
      "Model:                          Logit   Df Residuals:                    67777\n",
      "Method:                           MLE   Df Model:                           27\n",
      "Date:                Sun, 22 Mar 2020   Pseudo R-squ.:                 0.02950\n",
      "Time:                        16:05:12   Log-Likelihood:                -45250.\n",
      "converged:                       True   LL-Null:                       -46625.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "====================================================================================================\n",
      "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "annual_inc_log                      -0.0443      0.011     -4.056      0.000      -0.066      -0.023\n",
      "credit_hist_mths                     0.0277      0.009      3.139      0.002       0.010       0.045\n",
      "delinq_amnt_log                      0.0090      0.010      0.865      0.387      -0.011       0.029\n",
      "dti_log                             -0.0282      0.010     -2.835      0.005      -0.048      -0.009\n",
      "emp_length                          -0.0076      0.008     -0.932      0.351      -0.024       0.008\n",
      "fico_range_high                     -0.1511      0.012    -13.110      0.000      -0.174      -0.129\n",
      "funded_amnt_log                      7.9781      0.389     20.499      0.000       7.215       8.741\n",
      "grade                               -0.1097      0.026     -4.224      0.000      -0.161      -0.059\n",
      "has_36mo_loan                        1.8342      0.089     20.575      0.000       1.660       2.009\n",
      "has_delinq_now                       0.0091      0.010      0.876      0.381      -0.011       0.029\n",
      "has_delinq_past2yrs                  0.0369      0.008      4.368      0.000       0.020       0.053\n",
      "has_pub_rec                         -0.0294      0.009     -3.430      0.001      -0.046      -0.013\n",
      "has_whole_liststatus                -0.1921      0.008    -23.426      0.000      -0.208      -0.176\n",
      "inq_last_6mths                       0.0145      0.008      1.724      0.085      -0.002       0.031\n",
      "installment_log                     -7.5253      0.368    -20.441      0.000      -8.247      -6.804\n",
      "int_rate                             0.9882      0.050     19.584      0.000       0.889       1.087\n",
      "open_acc_log                         0.0295      0.013      2.302      0.021       0.004       0.055\n",
      "revol_bal_log                        0.0082      0.011      0.727      0.467      -0.014       0.030\n",
      "revol_util                           0.2490      0.012     21.039      0.000       0.226       0.272\n",
      "tot_coll_amt_log                     0.0667      0.008      8.036      0.000       0.050       0.083\n",
      "tot_cur_bal_log                     -0.0273      0.012     -2.326      0.020      -0.050      -0.004\n",
      "total_acc_log                       -0.0540      0.012     -4.324      0.000      -0.078      -0.030\n",
      "home_ownership_own                  -0.0215      0.009     -2.491      0.013      -0.038      -0.005\n",
      "home_ownership_rent                 -0.0300      0.010     -2.929      0.003      -0.050      -0.010\n",
      "purpose_credit_card                 -0.0002      0.008     -0.028      0.978      -0.017       0.016\n",
      "purpose_other                       -0.0255      0.009     -2.905      0.004      -0.043      -0.008\n",
      "verification_status_Not Verified     0.0088      0.009      0.968      0.333      -0.009       0.027\n",
      "verification_status_Verified         0.0330      0.009      3.679      0.000       0.015       0.051\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "result = sm.Logit(class_response,df_feature_final_scaled).fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=-1, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': array([1.00000000e-05, 1.29154967e-04, 1.66810054e-03, 2.15443469e-02,\n",
       "       2.78255940e-01, 3.59381366e+00, 4.64158883e+01, 5.99484250e+02,\n",
       "       7.74263683e+03, 1.00000000e+05]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "lr = LogisticRegression(n_jobs=-1)\n",
    "c_param = {'C':np.logspace(-5,5,10),'penalty':['l1','l2']}\n",
    "gs_lr = GridSearchCV(lr, c_param, cv=5, scoring='accuracy')\n",
    "gs_lr.fit(df_feature_final_scaled,class_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.0016681005372000592, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5977287810633434"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model accuracy\n",
    "gs_lr.score(df_feature_final_scaled,class_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5524371359044318"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Population accuracy\n",
    "class_response['roi_response'].value_counts()[1]/(class_response['roi_response'].value_counts()[0]+class_response['roi_response'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11652, 18695],\n",
       "       [ 8581, 28877]])"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Type I error is very high\n",
    "con_matrix = confusion_matrix(class_response, gs_lr.best_estimator_.predict(df_feature_final_scaled))\n",
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for predicting below 10 percentage threshold: 0.383959\n",
      "Accuracy for predicting above 10 percentage threshold: 0.770917\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.diag(con_matrix/con_matrix.sum(axis=1).reshape((-1,1)))\n",
    "print('Accuracy for predicting below 10 percentage threshold: %f' %accuracy[0])\n",
    "print('Accuracy for predicting above 10 percentage threshold: %f' %accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection Using Lasso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annual_inc_log',\n",
       " 'fico_range_high',\n",
       " 'has_whole_liststatus',\n",
       " 'revol_util',\n",
       " 'tot_coll_amt_log',\n",
       " 'total_acc_log'}"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = SelectFromModel(LogisticRegression(C=gs_lr.best_params_[\"C\"], penalty=gs_lr.best_params_[\"penalty\"]))\n",
    "sel.fit(df_feature_final_scaled, class_response)\n",
    "\n",
    "# Features selected\n",
    "selected_feat = df_feature_final_scaled.columns[(sel.get_support())]\n",
    "set(np.array(selected_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'credit_hist_mths',\n",
       " 'delinq_amnt_log',\n",
       " 'dti_log',\n",
       " 'emp_length',\n",
       " 'funded_amnt_log',\n",
       " 'grade',\n",
       " 'has_36mo_loan',\n",
       " 'has_delinq_now',\n",
       " 'has_delinq_past2yrs',\n",
       " 'has_pub_rec',\n",
       " 'home_ownership_own',\n",
       " 'home_ownership_rent',\n",
       " 'inq_last_6mths',\n",
       " 'installment_log',\n",
       " 'int_rate',\n",
       " 'open_acc_log',\n",
       " 'purpose_credit_card',\n",
       " 'purpose_other',\n",
       " 'revol_bal_log',\n",
       " 'tot_cur_bal_log',\n",
       " 'verification_status_Not Verified',\n",
       " 'verification_status_Verified'}"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features dropped\n",
    "set(df_feature_final_scaled.columns)-set(selected_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test Using Only 6 features  - generates similar results as GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_feature_final_scaled[selected_feat], class_response, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.594554\n",
      "Test accuracy: 0.610353\n",
      "Test Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2384, 3613],\n",
       "       [1671, 5893]])"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_train = LogisticRegression(C=gs_lr.best_params_[\"C\"], penalty=gs_lr.best_params_[\"penalty\"], n_jobs=-1)\n",
    "lr_train.fit(X_train,y_train)\n",
    "print(\"Train accuracy: %f\" %lr_train.score(X_train,y_train))\n",
    "print(\"Test accuracy: %f\" %lr_train.score(X_test,y_test))\n",
    "print(\"Test Confusion Matrix:\")\n",
    "confusion_matrix(y_test, lr_train.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model based on 5% threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_to_object_array' from 'sklearn.utils' (/Users/invincible/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-466-0b052d41b57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/imblearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mModule\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mallowing\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcreate\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mscikit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \"\"\"\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/imblearn/combine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_smote_enn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_smote_tomek\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/imblearn/combine/_smote_enn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseOverSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_sampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/imblearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_docstring\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSubstitution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_neighbors_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_sampling_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_to_object_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_to_object_array' from 'sklearn.utils' (/Users/invincible/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.676850\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         roi_response_5   No. Observations:                67805\n",
      "Model:                          Logit   Df Residuals:                    67777\n",
      "Method:                           MLE   Df Model:                           27\n",
      "Date:                Sun, 22 Mar 2020   Pseudo R-squ.:                 -0.1328\n",
      "Time:                        16:42:34   Log-Likelihood:                -45894.\n",
      "converged:                       True   LL-Null:                       -40513.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "====================================================================================================\n",
      "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "annual_inc_log                      -0.0006      0.011     -0.058      0.953      -0.022       0.020\n",
      "credit_hist_mths                     0.0120      0.009      1.378      0.168      -0.005       0.029\n",
      "delinq_amnt_log                      0.0033      0.010      0.319      0.749      -0.017       0.023\n",
      "dti_log                             -0.0518      0.010     -5.276      0.000      -0.071      -0.033\n",
      "emp_length                          -0.0157      0.008     -1.932      0.053      -0.032       0.000\n",
      "fico_range_high                     -0.0208      0.011     -1.849      0.064      -0.043       0.001\n",
      "funded_amnt_log                      1.9555      0.385      5.081      0.000       1.201       2.710\n",
      "grade                               -0.0561      0.026     -2.172      0.030      -0.107      -0.005\n",
      "has_36mo_loan                        0.5633      0.088      6.382      0.000       0.390       0.736\n",
      "has_delinq_now                       0.0070      0.010      0.677      0.498      -0.013       0.027\n",
      "has_delinq_past2yrs                  0.0248      0.008      2.950      0.003       0.008       0.041\n",
      "has_pub_rec                         -0.0052      0.009     -0.611      0.541      -0.022       0.012\n",
      "has_whole_liststatus                -0.1244      0.008    -15.255      0.000      -0.140      -0.108\n",
      "inq_last_6mths                      -0.0165      0.008     -1.988      0.047      -0.033      -0.000\n",
      "installment_log                     -1.8540      0.364     -5.092      0.000      -2.568      -1.140\n",
      "int_rate                             0.0365      0.049      0.737      0.461      -0.061       0.133\n",
      "open_acc_log                        -0.0208      0.013     -1.640      0.101      -0.046       0.004\n",
      "revol_bal_log                        0.0310      0.011      2.808      0.005       0.009       0.053\n",
      "revol_util                           0.1277      0.012     10.904      0.000       0.105       0.151\n",
      "tot_coll_amt_log                     0.0382      0.008      4.635      0.000       0.022       0.054\n",
      "tot_cur_bal_log                      0.0235      0.012      2.023      0.043       0.001       0.046\n",
      "total_acc_log                       -0.0039      0.012     -0.316      0.752      -0.028       0.020\n",
      "home_ownership_own                  -0.0253      0.009     -2.959      0.003      -0.042      -0.009\n",
      "home_ownership_rent                 -0.0516      0.010     -5.083      0.000      -0.071      -0.032\n",
      "purpose_credit_card                  0.0138      0.008      1.666      0.096      -0.002       0.030\n",
      "purpose_other                       -0.0586      0.009     -6.744      0.000      -0.076      -0.042\n",
      "verification_status_Not Verified     0.0366      0.009      4.097      0.000       0.019       0.054\n",
      "verification_status_Verified         0.0167      0.009      1.870      0.061      -0.001       0.034\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "result_5 = sm.Logit(class_response_5,df_feature_final_scaled).fit()\n",
    "print(result_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=-1, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': array([1.00000000e-05, 1.29154967e-04, 1.66810054e-03, 2.15443469e-02,\n",
       "       2.78255940e-01, 3.59381366e+00, 4.64158883e+01, 5.99484250e+02,\n",
       "       7.74263683e+03, 1.00000000e+05]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search for C value and L1/L2 \n",
    "%time\n",
    "\n",
    "lr_5 = LogisticRegression(n_jobs=-1)\n",
    "c_param = {'C':np.logspace(-5,5,10),'penalty':['l1','l2']}\n",
    "gs_lr_5 = GridSearchCV(lr_5, c_param, cv=5, scoring='accuracy')\n",
    "gs_lr_5.fit(df_feature_final_scaled,class_response_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.0001291549665014884, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715124253373645"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_5.score(df_feature_final_scaled,class_response_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715124253373645"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_response_5['roi_response_5'].value_counts()[1]/(class_response_5['roi_response_5'].value_counts()[0]+class_response_5['roi_response_5'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6332, 12984],\n",
       "       [13901, 34588]])"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_matrix_5 = confusion_matrix(class_response_5, gs_lr.best_estimator_.predict(df_feature_final_scaled))\n",
    "con_matrix_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for predicting below 10 percentage threshold: 0.327811\n",
      "Accuracy for predicting above 10 percentage threshold: 0.713316\n"
     ]
    }
   ],
   "source": [
    "accuracy_5 = np.diag(con_matrix_5/con_matrix_5.sum(axis=1).reshape((-1,1)))\n",
    "print('Accuracy for predicting below 10 percentage threshold: %f' %accuracy_5[0])\n",
    "print('Accuracy for predicting above 10 percentage threshold: %f' %accuracy_5[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_5 = SelectFromModel(LogisticRegression(C=gs_lr_5.best_params_[\"C\"], penalty=gs_lr_5.best_params_[\"penalty\"]))\n",
    "sel_5.fit(df_feature_final_scaled, class_response_5)\n",
    "\n",
    "# Features selected\n",
    "selected_feat_5 = df_feature_final_scaled.columns[(sel_5.get_support())]\n",
    "set(np.array(selected_feat_5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annual_inc_log',\n",
       " 'credit_hist_mths',\n",
       " 'delinq_amnt_log',\n",
       " 'dti_log',\n",
       " 'emp_length',\n",
       " 'fico_range_high',\n",
       " 'funded_amnt_log',\n",
       " 'grade',\n",
       " 'has_36mo_loan',\n",
       " 'has_delinq_now',\n",
       " 'has_delinq_past2yrs',\n",
       " 'has_pub_rec',\n",
       " 'has_whole_liststatus',\n",
       " 'home_ownership_own',\n",
       " 'home_ownership_rent',\n",
       " 'inq_last_6mths',\n",
       " 'installment_log',\n",
       " 'int_rate',\n",
       " 'open_acc_log',\n",
       " 'purpose_credit_card',\n",
       " 'purpose_other',\n",
       " 'revol_bal_log',\n",
       " 'revol_util',\n",
       " 'tot_coll_amt_log',\n",
       " 'tot_cur_bal_log',\n",
       " 'total_acc_log',\n",
       " 'verification_status_Not Verified',\n",
       " 'verification_status_Verified'}"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features dropped\n",
    "set(df_feature_final_scaled.columns)-set(selected_feat_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.447626\n",
      "Test accuracy: 0.447312\n",
      "Test Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6066,    0],\n",
       "       [7495,    0]])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_5_train = LogisticRegression(C=gs_lr_5.best_params_[\"C\"], penalty=gs_lr_5.best_params_[\"penalty\"], n_jobs=-1 )\n",
    "lr_5_train.fit(X_train,y_train)\n",
    "print(\"Train accuracy: %f\" %lr_5_train.score(X_train,y_train))\n",
    "print(\"Test accuracy: %f\" %lr_5_train.score(X_test,y_test))\n",
    "print(\"Test Confusion Matrix:\")\n",
    "confusion_matrix(y_test, lr_5_train.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "- Goal is to build classifier that predicts if loan results in desirable outcome\n",
    "- Should also report feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "\n",
    "#Create test-train split of data\n",
    "x = df_final\n",
    "y = df_cleaned[response_var] #labels\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create random forest object\n",
    "# randomForest = ensemble.RandomForestClassifier()\n",
    "\n",
    "# #Set random forest parameters\n",
    "# randomForest.set_params(random_state=0)\n",
    "\n",
    "# #Fit model with data\n",
    "# randomForest.fit(x_train, y_train)\n",
    "\n",
    "# #Calculate the train and test accuracy\n",
    "# train_acc = randomForest.score(x_train, y_train)\n",
    "# test_acc = randomForest.score(x_test, y_test)\n",
    "\n",
    "# print('The training error is: .5f' % train_acc)\n",
    "# print('The test error is: %.5f' % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Partial Dependence Plot\n",
    "- Link https://towardsdatascience.com/introducing-pdpbox-2aa820afd312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survival Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KM Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cox model**\n",
    "- Use same predictors as random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
