{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Club: Machine Learning Capstone Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from time import strptime  # format data columns\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # ignore warnings throughout notebook\n",
    "pd.set_option(\"display.max_columns\", None)  # show all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "filepath = \"./data/accepted_subsampled_5percent.csv\" #will be personalized\n",
    "df = pd.read_csv(filepath, sep=\",\")\n",
    "\n",
    "df_cleaned = df.copy() #work from second copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features known to investors based on LC website\n",
    "known_vars = ['acc_now_delinq',             # accounts now deliquent\n",
    "              'collections_12_mths_ex_med', # collections excluding medical\n",
    "              'fico_range_high',            # credit score range\n",
    "              'fico_range_low',             # creit score range\n",
    "              'delinq_2yrs',                # delinquencies in last two years\n",
    "              'delinq_amnt',                # delinquency amount\n",
    "              'earliest_cr_line',           # earliest credit line\n",
    "              'home_ownership',             # home ownership\n",
    "              'dti',                        # debt2income ratio\n",
    "              'annual_inc',                 # annual income\n",
    "              'initial_list_status',        # initial listing status\n",
    "              'inq_last_6mths',             # credit inquires in last 6mo\n",
    "              'int_rate',                   # interest rate\n",
    "              'verification_status_joint',  # is this a joint app\n",
    "              'emp_length',                 # length of employment (yr)\n",
    "              'loan_amnt',                  # loan amount\n",
    "              'id',                         # loan id\n",
    "              'purpose',                    # purpose of the loan\n",
    "              'term',                       # loan term (3 or 5yr)\n",
    "              'addr_state',                 # borrower location state\n",
    "              'installment',                # montly payment\n",
    "              'mths_since_last_delinq',     # mo since last delinquency\n",
    "              'mths_since_last_major_derog',# mo since last maj. derogatory\n",
    "              'mths_since_last_record',     # mo since last public record\n",
    "              'open_acc',                   # open credit line\n",
    "              'pub_rec',                    # public records on file\n",
    "              'revol_util',                 # revolving balance utilization (%)\n",
    "              'revol_bal',                  # revolving credit balance ($)\n",
    "              'tot_coll_amt',               # total collection amount ever\n",
    "              'total_acc',                  # total credit lines\n",
    "              'tot_cur_bal',                # total current balance\n",
    "              'verification_status',        # verified income (Y/N I think)\n",
    "              'grade'                       # loan grade\n",
    "             ]\n",
    "\n",
    "# Sanity check, print variable if not found within original dataframe\n",
    "# [ print(var) for var in known_vars if (var not in df.columns)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Missing Data of Known Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verification_status_joint      0.949313\n",
       "mths_since_last_record         0.838543\n",
       "mths_since_last_major_derog    0.744395\n",
       "mths_since_last_delinq         0.513786\n",
       "emp_length                     0.063868\n",
       "tot_cur_bal                    0.033430\n",
       "tot_coll_amt                   0.033430\n",
       "revol_util                     0.001006\n",
       "dti                            0.000829\n",
       "collections_12_mths_ex_med     0.000476\n",
       "open_acc                       0.000185\n",
       "pub_rec                        0.000185\n",
       "total_acc                      0.000185\n",
       "inq_last_6mths                 0.000185\n",
       "earliest_cr_line               0.000185\n",
       "delinq_amnt                    0.000185\n",
       "delinq_2yrs                    0.000185\n",
       "acc_now_delinq                 0.000185\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assess missingness of known variables\n",
    "missingness = df_cleaned[known_vars].isnull().mean().T\n",
    "missingness = missingness.loc[missingness>0].sort_values(ascending=False)\n",
    "missingness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop features missing > 50% \n",
    "feat_wManyMissing = missingness.index[np.where(missingness > .5)].to_list()\n",
    "df_cleaned[known_vars].drop(df_cleaned[feat_wManyMissing], axis=1, inplace=True)\n",
    "[known_vars.remove(var) for var in feat_wManyMissing] #remove features from known_var list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace NA's of numeric 'known_var' features with mean value\n",
    "numeric_var = ['tot_cur_bal',\n",
    "               'tot_coll_amt',\n",
    "               'revol_util',\n",
    "               'collections_12_mths_ex_med',\n",
    "               'open_acc',\n",
    "               'pub_rec',\n",
    "               'total_acc',\n",
    "               'inq_last_6mths',\n",
    "               'delinq_amnt',\n",
    "               'delinq_2yrs',\n",
    "               'dti' ]\n",
    "\n",
    "# List comprehension through numerica variables\n",
    "[df_cleaned[var].fillna(df[var].mean(), inplace=True) for var in numeric_var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper function to replace missing character strings with randomly selected value\n",
    "def fillna_random(var):\n",
    "    #find index of missing values\n",
    "    miss_idx = df_cleaned.loc[ df_cleaned[var].isnull()].index.tolist()\n",
    "    \n",
    "    #find new values to replace NaN values\n",
    "    new_val = df_cleaned[var].loc[~df_cleaned.index.isin(miss_idx)].sample(len(miss_idx)).values.tolist()\n",
    "\n",
    "    #replace values\n",
    "    df_cleaned[var][miss_idx] = new_val\n",
    "\n",
    "# ==================================================\n",
    "# Replace NA's of character 'known_var' features with random\n",
    "non_numeric_var = ['emp_length', 'earliest_cr_line', 'acc_now_delinq', 'delinq_2yrs'] #list of non-numeric variables\n",
    "[fillna_random(var) for var in non_numeric_var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc_now_delinq                0\n",
       "collections_12_mths_ex_med    0\n",
       "fico_range_high               0\n",
       "fico_range_low                0\n",
       "delinq_2yrs                   0\n",
       "delinq_amnt                   0\n",
       "earliest_cr_line              0\n",
       "home_ownership                0\n",
       "dti                           0\n",
       "annual_inc                    0\n",
       "initial_list_status           0\n",
       "inq_last_6mths                0\n",
       "int_rate                      0\n",
       "emp_length                    0\n",
       "loan_amnt                     0\n",
       "id                            0\n",
       "purpose                       0\n",
       "term                          0\n",
       "addr_state                    0\n",
       "installment                   0\n",
       "open_acc                      0\n",
       "pub_rec                       0\n",
       "revol_util                    0\n",
       "revol_bal                     0\n",
       "tot_coll_amt                  0\n",
       "total_acc                     0\n",
       "tot_cur_bal                   0\n",
       "verification_status           0\n",
       "grade                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check that no more missing values\n",
    "df_cleaned[known_vars].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'C', 'A', 'E', 'D', 'F', 'G'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['grade'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify loan status (non-FullyPaid or ChargedOff loans will be converted to NAN)\n",
    "df_cleaned['loan_status'] = df_cleaned['loan_status'].map({'Fully Paid':'Fully Paid',\n",
    "                                                           'Charged Off':'Charged Off',\n",
    "                                                           'Does not meet the credit policy. Status:Fully Paid': 'Fully Paid',\n",
    "                                                           'Does not meet the credit policy. Status:Charged Off': 'Charged Off'})\n",
    "\n",
    "# Remove non-completed loans\n",
    "df_cleaned.drop(df_cleaned.loc[df_cleaned['loan_status'].isnull()].index.tolist(), axis=0, inplace=True)\n",
    "\n",
    "# Simplify home ownership\n",
    "df_cleaned['home_ownership'] = df_cleaned['home_ownership'].map({'MORTGAGE':'mortgage',\n",
    "                                                                 'OWN':'own',\n",
    "                                                                 'RENT':'rent'})\n",
    "\n",
    "# Remove 25 observations without houses\n",
    "df_cleaned.drop(df_cleaned.loc[df_cleaned['home_ownership'].isnull()].index.tolist(), axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Reformat date features and calculate features related to prepayment  \n",
    "df_cleaned['term_year'] = np.where(df_cleaned['term']==' 36 months', 3,5)\n",
    "df_cleaned['earliest_cr_line'] =  pd.to_datetime(df_cleaned['earliest_cr_line'])\n",
    "df_cleaned['issue_date'] =  pd.to_datetime(df_cleaned['issue_d'])\n",
    "df_cleaned['last_pymnt_date'] = pd.to_datetime(df_cleaned['last_pymnt_d'])\n",
    "df_cleaned['exp_last_pymnt_date'] = pd.to_datetime(df_cleaned['issue_d'].str[0:3]\n",
    "                                                   +'-'\n",
    "                                                   + (df_cleaned['issue_d'].str[-4:].astype('int')\n",
    "                                                   + df_cleaned['term_year']).astype('str'))\n",
    "\n",
    "# Calculate credit history ( in months )\n",
    "date_ofloan = df_cleaned['issue_date'].dt.to_period('M').astype(int)\n",
    "date_credline = df_cleaned['earliest_cr_line'].dt.to_period('M').astype(int)\n",
    "df_cleaned['credit_hist_mths'] = date_ofloan - date_credline\n",
    "\n",
    "# Log-transform skewed continuous features\n",
    "df_cleaned['delinq_amnt_log'] = df_cleaned['delinq_amnt'].add(1).apply(np.log)\n",
    "df_cleaned['annual_inc_log'] = df_cleaned['annual_inc'].add(1).apply(np.log)\n",
    "df_cleaned['dti_log'] = df_cleaned['dti'].add(1).apply(np.log)\n",
    "df_cleaned['funded_amnt_log'] = df_cleaned['funded_amnt'].add(1).apply(np.log)\n",
    "df_cleaned['tot_coll_amt_log'] = df_cleaned['tot_coll_amt'].add(1).apply(np.log)\n",
    "df_cleaned['tot_cur_bal_log'] = df_cleaned['tot_cur_bal'].add(1).apply(np.log)\n",
    "df_cleaned['total_acc_log'] = df_cleaned['total_acc'].add(1).apply(np.log)\n",
    "df_cleaned['revol_bal_log'] = df_cleaned['revol_bal'].add(1).apply(np.log)\n",
    "df_cleaned['installment_log'] = df_cleaned['installment'].add(1).apply(np.log)\n",
    "df_cleaned['open_acc_log'] = df_cleaned['open_acc'].add(1).apply(np.log)\n",
    "\n",
    "# Simplify employment length to four categories\n",
    "df_cleaned['emp_length'] = df_cleaned['emp_length'].map({'< 1 year':'less 1yr',\n",
    "                                                         '1 year':'1-3yrs',\n",
    "                                                         '2 years':'1-3yrs',\n",
    "                                                         '3 years':'1-3yrs',\n",
    "                                                         '4 years':'4-7yrs',\n",
    "                                                         '5 years':'4-7yrs',\n",
    "                                                         '6 years':'4-7yrs',\n",
    "                                                         '7 years':'7+yrs',\n",
    "                                                         '8 years':'7+yrs',\n",
    "                                                         '9 years':'7+yrs',\n",
    "                                                         '10+ years':'7+yrs'})\n",
    "\n",
    "# Simplify loan purpose - debt consolidation, credit card, and other\n",
    "df_cleaned['purpose'] = df_cleaned['purpose'].map({'debt_consolidation':'debt_consolidation',\n",
    "                                                   'credit_card':'credit_card'})\n",
    "df_cleaned['purpose'].fillna('other',inplace=True)\n",
    "\n",
    "# Convert loan grade to ordinal\n",
    "df_cleaned['grade'] = df_cleaned['grade'].map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'G':7})\n",
    "\n",
    "# Create new binary features\n",
    "df_cleaned['has_pub_rec'] = np.where(df_cleaned['pub_rec']>0,1,0) #0-=no public record\n",
    "df_cleaned['has_paid_early'] = np.where((df_cleaned.loan_status=='Fully Paid')&(df_cleaned.last_pymnt_date < df_cleaned.exp_last_pymnt_date), 1, 0)\n",
    "df_cleaned['has_36mo_loan'] = np.where(df_cleaned['term'].str.contains('36'),1,0) #0=60mo loan\n",
    "df_cleaned['has_delinq_now'] = np.where(df_cleaned['acc_now_delinq']>0, 1, 0)\n",
    "df_cleaned['has_delinq_past2yrs'] = np.where(df_cleaned['delinq_2yrs']>0, 1, 0) #0=no delinq within 2yrs\n",
    "df_cleaned['has_whole_liststatus'] = np.where(df_cleaned['initial_list_status']=='w', 1, 0) #0=f\n",
    "df_cleaned['has_fullypaid'] = np.where(df_cleaned['loan_status']=='Fully Paid', 1, 0) #0=charged off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create response variable based on \n",
    "threshold = 10 #goal of loans is loss of <10%\n",
    "df_cleaned[\"roi_perc\"] = df_cleaned[\"total_pymnt\"].div(df_cleaned[\"funded_amnt\"]).sub(1).mul(100)\n",
    "df_cleaned['roi_response'] = np.where(df_cleaned['roi_perc'] > threshold, 1, 0) #84% of all loans > -20% ROI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate list of predictor variables to be used for ML\n",
    "predictor_vars = ['annual_inc_log',\n",
    "                  'credit_hist_mths',\n",
    "                  'delinq_amnt_log',\n",
    "                  'dti_log',\n",
    "                  'emp_length',\n",
    "                  'fico_range_high',\n",
    "                  'funded_amnt_log',\n",
    "                  'grade',\n",
    "                  'has_36mo_loan',\n",
    "                  'has_delinq_now',\n",
    "                  'has_delinq_past2yrs',\n",
    "#                   'has_fullypaid',\n",
    "#                   'has_paid_early',\n",
    "                  'has_pub_rec',\n",
    "                  'has_whole_liststatus',\n",
    "                  'home_ownership',\n",
    "                  'inq_last_6mths',\n",
    "                  'installment_log',\n",
    "                  'int_rate',\n",
    "                  'open_acc_log',\n",
    "                  'purpose',\n",
    "                  'revol_bal_log',\n",
    "                  'revol_util',\n",
    "                  'tot_coll_amt_log',\n",
    "                  'tot_cur_bal_log',\n",
    "                  'total_acc_log',\n",
    "                  'verification_status']\n",
    "\n",
    "response_var = 'roi_response'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "- Goal is to build classifier that predicts if loan results in desirable outcome\n",
    "- Should also report feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify categorical features\n",
    "emp_length_dummy = pd.get_dummies(df_cleaned['emp_length'],\n",
    "                                  prefix=\"emp_length\").drop('emp_length_7+yrs',axis=1)\n",
    "\n",
    "\n",
    "home_ownership_dummy = pd.get_dummies(df_cleaned['home_ownership'],\n",
    "                                      prefix=\"home_ownership\").drop('home_ownership_mortgage',axis=1)\n",
    "\n",
    "\n",
    "\n",
    "purpose_dummy = pd.get_dummies(df_cleaned['purpose'],\n",
    "                               prefix=\"purpose\").drop('purpose_debt_consolidation',axis=1)\n",
    "\n",
    "\n",
    "verification_status_dummy = pd.get_dummies(df_cleaned['verification_status'],\n",
    "                               prefix=\"verification_status\").drop('verification_status_Source Verified',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numeric features in the final dataframe\n",
    "numeric_vars = ['annual_inc_log',\n",
    "                  'credit_hist_mths',\n",
    "                  'delinq_amnt_log',\n",
    "                  'dti_log',\n",
    "#                   'emp_length',\n",
    "                  'fico_range_high',\n",
    "                  'funded_amnt_log',\n",
    "                  'grade',\n",
    "                  'has_36mo_loan',\n",
    "                  'has_delinq_now',\n",
    "                  'has_delinq_past2yrs',\n",
    "                  'has_pub_rec',\n",
    "                  'has_whole_liststatus',\n",
    "#                   'home_ownership',\n",
    "                  'inq_last_6mths',\n",
    "                  'installment_log',\n",
    "                  'int_rate',\n",
    "                  'open_acc_log',\n",
    "#                   'purpose',\n",
    "                  'revol_bal_log',\n",
    "                  'revol_util',\n",
    "                  'tot_coll_amt_log',\n",
    "                  'tot_cur_bal_log',\n",
    "                  'total_acc_log',\n",
    "#                   'verification_status'\n",
    "                 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annual_inc_log                      0\n",
       "credit_hist_mths                    0\n",
       "delinq_amnt_log                     0\n",
       "dti_log                             0\n",
       "fico_range_high                     0\n",
       "funded_amnt_log                     0\n",
       "grade                               0\n",
       "has_36mo_loan                       0\n",
       "has_delinq_now                      0\n",
       "has_delinq_past2yrs                 0\n",
       "has_pub_rec                         0\n",
       "has_whole_liststatus                0\n",
       "inq_last_6mths                      0\n",
       "installment_log                     0\n",
       "int_rate                            0\n",
       "open_acc_log                        0\n",
       "revol_bal_log                       0\n",
       "revol_util                          0\n",
       "tot_coll_amt_log                    0\n",
       "tot_cur_bal_log                     0\n",
       "total_acc_log                       0\n",
       "emp_length_1-3yrs                   0\n",
       "emp_length_4-7yrs                   0\n",
       "emp_length_less 1yr                 0\n",
       "home_ownership_own                  0\n",
       "home_ownership_rent                 0\n",
       "purpose_credit_card                 0\n",
       "purpose_other                       0\n",
       "verification_status_Not Verified    0\n",
       "verification_status_Verified        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final dataframe for model consumption\n",
    "df_final = pd.concat([df_cleaned[numeric_vars],\n",
    "                      emp_length_dummy,\n",
    "                      home_ownership_dummy,\n",
    "                      purpose_dummy,\n",
    "                      verification_status_dummy],axis=1)\n",
    "\n",
    "#Sanity Check\n",
    "df_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "- Goal is to build classifier that predicts if loan results in desirable outcome\n",
    "- Should also report feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categorical features into numbers\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lencoder = LabelEncoder()\n",
    "\n",
    "#emp_length, home_ownership, purpose, verification_status features to encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "\n",
    "#Create test-train split of data\n",
    "x = df_cleaned[predictor_vars]\n",
    "y = df_cleaned[response_var] #labels\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1-3yrs', 'less 1yr', '4-7yrs', '7+yrs'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.emp_length.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '4-7yrs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-aa2dd1932ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Fit model with data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrandomForest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Calculate the train and test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '4-7yrs'"
     ]
    }
   ],
   "source": [
    "#Create random forest object\n",
    "randomForest = ensemble.RandomForestClassifier()\n",
    "\n",
    "#Set random forest parameters\n",
    "randomForest.set_params(random_state=0)\n",
    "\n",
    "#Fit model with data\n",
    "randomForest.fit(x_train, y_train)\n",
    "\n",
    "#Calculate the train and test accuracy\n",
    "train_acc = randomForest.score(x_train, y_train)\n",
    "test_acc = randomForest.score(x_test, y_test)\n",
    "\n",
    "print('The training error is: .5f' % train_acc)\n",
    "print('The test error is: %.5f' % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Partial Dependence Plot\n",
    "- Link https://towardsdatascience.com/introducing-pdpbox-2aa820afd312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survival Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KM Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cox model**\n",
    "- Use same predictors as random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
